{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'img_id': 1, 'img_name': 'xmlab1/source.jpg', 'question': 'What modality is used to take this image?', 'answer': 'MRI', 'q_lang': 'en', 'location': 'Abdomen', 'modality': 'MRI', 'answer_type': 'OPEN', 'base_type': 'vqa', 'content_type': 'Modality', 'triple': ['vhead', '_', '_'], 'qid': 0}, {'img_id': 1, 'img_name': 'xmlab1/source.jpg', 'question': 'Which part of the body does this image belong to?', 'answer': 'Abdomen', 'q_lang': 'en', 'location': 'Abdomen', 'modality': 'MRI', 'answer_type': 'OPEN', 'base_type': 'vqa', 'content_type': 'Position', 'triple': ['vhead', '_', '_'], 'qid': 1}, {'img_id': 1, 'img_name': 'xmlab1/source.jpg', 'question': 'What is the mr weighting in this image?', 'answer': 'T2', 'q_lang': 'en', 'location': 'Abdomen', 'modality': 'MRI', 'answer_type': 'OPEN', 'base_type': 'vqa', 'content_type': 'Modality', 'triple': ['vhead', '_', '_'], 'qid': 2}]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Path to the original train.json file\n",
    "train_json_path = '/Users/jeffreysherer/Desktop/Dissertation/Slake1.0/train.json'\n",
    "\n",
    "# Load the train.json file\n",
    "with open(train_json_path, 'r') as file:\n",
    "    train_data = json.load(file)\n",
    "\n",
    "# Display the first few entries to verify the content\n",
    "print(train_data[:3])  # Adjust the number of entries to display based on your need\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Liver': [54.0, 106.0, 30.0, 31.0]}]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def load_detection_json(img_folder):\n",
    "    # Path to the folder containing detection.json\n",
    "    detection_json_path = os.path.join('/Users/jeffreysherer/Dissertation/data/imgs-1', img_folder, 'detection.json')\n",
    "    \n",
    "    # Load the detection.json file\n",
    "    if os.path.exists(detection_json_path):\n",
    "        with open(detection_json_path, 'r') as file:\n",
    "            detection_data = json.load(file)\n",
    "        return detection_data\n",
    "    else:\n",
    "        return None  # Return None if file does not exist\n",
    "\n",
    "# Test the function with an example folder\n",
    "example_folder = 'xmlab1'\n",
    "example_detection = load_detection_json(example_folder)\n",
    "print(example_detection)  # Display the content of the detection.json for verification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'img_id': 1, 'img_name': 'xmlab1/source.jpg', 'question': 'What modality is used to take this image?', 'answer': 'MRI', 'q_lang': 'en', 'location': 'Abdomen', 'modality': 'MRI', 'answer_type': 'OPEN', 'base_type': 'vqa', 'content_type': 'Modality', 'triple': ['vhead', '_', '_'], 'qid': 0, 'detection': [{'Liver': [54.0, 106.0, 30.0, 31.0]}]}, {'img_id': 1, 'img_name': 'xmlab1/source.jpg', 'question': 'Which part of the body does this image belong to?', 'answer': 'Abdomen', 'q_lang': 'en', 'location': 'Abdomen', 'modality': 'MRI', 'answer_type': 'OPEN', 'base_type': 'vqa', 'content_type': 'Position', 'triple': ['vhead', '_', '_'], 'qid': 1, 'detection': [{'Liver': [54.0, 106.0, 30.0, 31.0]}]}, {'img_id': 1, 'img_name': 'xmlab1/source.jpg', 'question': 'What is the mr weighting in this image?', 'answer': 'T2', 'q_lang': 'en', 'location': 'Abdomen', 'modality': 'MRI', 'answer_type': 'OPEN', 'base_type': 'vqa', 'content_type': 'Modality', 'triple': ['vhead', '_', '_'], 'qid': 2, 'detection': [{'Liver': [54.0, 106.0, 30.0, 31.0]}]}]\n"
     ]
    }
   ],
   "source": [
    "# Function to add detection data to train_data entries\n",
    "def integrate_detection_data(train_data):\n",
    "    for item in train_data:\n",
    "        # Extract the folder name from img_name\n",
    "        folder_name = item['img_name'].split('/')[0]\n",
    "        \n",
    "        # Load detection data for the corresponding folder\n",
    "        detection_data = load_detection_json(folder_name)\n",
    "        \n",
    "        # If detection data exists, add it to the train data item\n",
    "        if detection_data:\n",
    "            item['detection'] = detection_data\n",
    "    \n",
    "    return train_data\n",
    "\n",
    "# Update train_data with detection information\n",
    "updated_train_data = integrate_detection_data(train_data)\n",
    "\n",
    "# Print a few updated entries to verify that detection data has been added correctly\n",
    "print(updated_train_data[:3])  # Adjust the number of entries to display based on your need\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final train.json has been saved to /Users/jeffreysherer/Desktop/Dissertation/Slake1.0/augmented/final_train.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import uuid  # To generate unique IDs\n",
    "\n",
    "# Base path where the original train.json is located\n",
    "base_path = '/Users/jeffreysherer/Desktop/Dissertation/Slake1.0'\n",
    "\n",
    "# Directory for the augmented files\n",
    "augmented_dir = os.path.join(base_path, 'augmented')\n",
    "\n",
    "# Create the augmented directory if it doesn't exist\n",
    "os.makedirs(augmented_dir, exist_ok=True)\n",
    "\n",
    "# Directory containing the image folders with detection.json files\n",
    "image_directory = '/Users/jeffreysherer/Dissertation/data/imgs-1'\n",
    "\n",
    "# Path to the original train.json file\n",
    "train_json_path = os.path.join(base_path, 'train.json')\n",
    "\n",
    "# Load the train.json file\n",
    "with open(train_json_path, 'r') as file:\n",
    "    train_data = json.load(file)\n",
    "\n",
    "# Function to update the data with bounding box coordinates\n",
    "def update_data_with_bounding_boxes(data):\n",
    "    for entry in data:\n",
    "        img_folder = os.path.dirname(entry['img_name'])\n",
    "        detection_json_path = os.path.join(image_directory, img_folder, 'detection.json')\n",
    "\n",
    "        if os.path.exists(detection_json_path):\n",
    "            with open(detection_json_path, 'r') as file:\n",
    "                detection_data = json.load(file)\n",
    "            entry['detection'] = detection_data\n",
    "\n",
    "    return data\n",
    "\n",
    "# Update the train data with bounding box coordinates\n",
    "updated_train_data = update_data_with_bounding_boxes(train_data)\n",
    "\n",
    "# Function to transform the data to the required format\n",
    "def transform_data(data):\n",
    "    transformed_data = []\n",
    "    for entry in data:\n",
    "        unique_id = str(uuid.uuid4())  # Generate a unique ID for each entry\n",
    "        img_path = entry['img_name']  # Use the img_name as the image path\n",
    "        question = entry['question']\n",
    "        answer = entry['answer']\n",
    "        \n",
    "        transformed_entry = {\n",
    "            \"id\": unique_id,\n",
    "            \"image\": img_path,\n",
    "            \"conversations\": [\n",
    "                {\n",
    "                    \"from\": \"human\",\n",
    "                    \"value\": f\"<image>\\n{question}\"\n",
    "                },\n",
    "                {\n",
    "                    \"from\": \"gpt\",\n",
    "                    \"value\": answer\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "        if 'detection' in entry:\n",
    "            transformed_entry['detection'] = entry['detection']\n",
    "        transformed_data.append(transformed_entry)\n",
    "    return transformed_data\n",
    "\n",
    "# Transform the train data\n",
    "transformed_train_data = transform_data(updated_train_data)\n",
    "\n",
    "# Path to save the final train.json file\n",
    "final_train_json_path = os.path.join(augmented_dir, 'final_train.json')\n",
    "\n",
    "# Write the transformed train data to a new JSON file\n",
    "with open(final_train_json_path, 'w') as file:\n",
    "    json.dump(transformed_train_data, file, indent=4)\n",
    "\n",
    "print(\"Final train.json has been saved to\", final_train_json_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final train.json has been saved to /Users/jeffreysherer/Desktop/Dissertation/Slake1.0/augmented/final_train.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import uuid  # To generate unique IDs\n",
    "\n",
    "# Assuming 'updated_train_data' is already defined from the previous cell\n",
    "\n",
    "# Transform the data to the required format\n",
    "transformed_data = []\n",
    "for entry in updated_train_data:\n",
    "    unique_id = str(uuid.uuid4())  # Generate a unique ID for each entry\n",
    "    img_path = entry['img_name']  # Use the img_name as the image path\n",
    "    question = entry['question']\n",
    "    answer = entry['answer']\n",
    "    \n",
    "    transformed_entry = {\n",
    "        \"id\": unique_id,\n",
    "        \"image\": img_path,\n",
    "        \"conversations\": [\n",
    "            {\n",
    "                \"from\": \"human\",\n",
    "                \"value\": f\"<image>\\n{question}\"\n",
    "            },\n",
    "            {\n",
    "                \"from\": \"gpt\",\n",
    "                \"value\": answer\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    if 'detection' in entry:\n",
    "        transformed_entry['detection'] = entry['detection']\n",
    "    transformed_data.append(transformed_entry)\n",
    "\n",
    "# Path to save the final transformed JSON file\n",
    "final_train_json_path = '/Users/jeffreysherer/Desktop/Dissertation/Slake1.0/augmented/final_train.json'\n",
    "\n",
    "# Write the transformed data to a new JSON file\n",
    "with open(final_train_json_path, 'w') as file:\n",
    "    json.dump(transformed_data, file, indent=4)\n",
    "\n",
    "print(\"Final train.json has been saved to\", final_train_json_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"id\": \"a13bafb5-1129-4df1-a2f6-68cef4831a5f\",\n",
      "    \"image\": \"xmlab157/source.jpg\",\n",
      "    \"conversations\": [\n",
      "        {\n",
      "            \"from\": \"human\",\n",
      "            \"value\": \"<image>\\n\\u8fd9\\u5f20\\u56fe\\u7247\\u7684\\u6210\\u50cf\\u65b9\\u5f0f\\u662f\\u4ec0\\u4e48?\"\n",
      "        },\n",
      "        {\n",
      "            \"from\": \"gpt\",\n",
      "            \"value\": \"X-Ray\"\n",
      "        }\n",
      "    ],\n",
      "    \"detection\": [\n",
      "        {\n",
      "            \"Pneumonia\": [\n",
      "                113.0,\n",
      "                200.0,\n",
      "                227.0,\n",
      "                381.0\n",
      "            ]\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"id\": \"22088a0c-9c49-45e2-903d-6522b8e4734d\",\n",
      "    \"image\": \"xmlab141/source.jpg\",\n",
      "    \"conversations\": [\n",
      "        {\n",
      "            \"from\": \"human\",\n",
      "            \"value\": \"<image>\\nWhere is/are the abnormality located?\"\n",
      "        },\n",
      "        {\n",
      "            \"from\": \"gpt\",\n",
      "            \"value\": \"Right Lung, Left\"\n",
      "        }\n",
      "    ],\n",
      "    \"detection\": [\n",
      "        {\n",
      "            \"Mass\": [\n",
      "                290.0,\n",
      "                326.0,\n",
      "                153.0,\n",
      "                198.0\n",
      "            ]\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"id\": \"5041d819-3fa5-4623-8291-dbac5979d5ce\",\n",
      "    \"image\": \"xmlab268/source.jpg\",\n",
      "    \"conversations\": [\n",
      "        {\n",
      "            \"from\": \"human\",\n",
      "            \"value\": \"<image>\\n\\u56fe\\u7247\\u4e2d\\u4f53\\u79ef\\u6700\\u5927\\u7684\\u5668\\u5b98\\u662f\\u4ec0\\u4e48?\"\n",
      "        },\n",
      "        {\n",
      "            \"from\": \"gpt\",\n",
      "            \"value\": \"\\u80ba\"\n",
      "        }\n",
      "    ],\n",
      "    \"detection\": [\n",
      "        {\n",
      "            \"Liver\": [\n",
      "                85.0,\n",
      "                133.0,\n",
      "                174.0,\n",
      "                128.0\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"Liver Cancer\": [\n",
      "                240.0,\n",
      "                149.0,\n",
      "                13.0,\n",
      "                16.0\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"Liver Cancer\": [\n",
      "                181.0,\n",
      "                174.0,\n",
      "                12.0,\n",
      "                11.0\n",
      "            ]\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"id\": \"50d46002-4331-4231-9579-ec0d3e60e6b0\",\n",
      "    \"image\": \"xmlab559/source.jpg\",\n",
      "    \"conversations\": [\n",
      "        {\n",
      "            \"from\": \"human\",\n",
      "            \"value\": \"<image>\\n\\u56fe\\u7247\\u4e2d\\u54ea\\u4e2a\\u5668\\u5b98\\u5c5e\\u4e8e\\u6ccc\\u5c3f\\u7cfb\\u7edf?\"\n",
      "        },\n",
      "        {\n",
      "            \"from\": \"gpt\",\n",
      "            \"value\": \"\\u80be\\u810f\"\n",
      "        }\n",
      "    ],\n",
      "    \"detection\": [\n",
      "        {\n",
      "            \"Duodenum\": [\n",
      "                196.0,\n",
      "                204.0,\n",
      "                80.0,\n",
      "                30.0\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"Liver\": [\n",
      "                98.0,\n",
      "                201.0,\n",
      "                35.0,\n",
      "                73.0\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"Left Kidney\": [\n",
      "                293.0,\n",
      "                245.0,\n",
      "                56.0,\n",
      "                60.0\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"Spinal Cord\": [\n",
      "                234.0,\n",
      "                285.0,\n",
      "                15.0,\n",
      "                11.0\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"Right Kidney\": [\n",
      "                132.0,\n",
      "                259.0,\n",
      "                52.0,\n",
      "                48.0\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"Small Bowel\": [\n",
      "                112.0,\n",
      "                129.0,\n",
      "                273.0,\n",
      "                153.0\n",
      "            ]\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"id\": \"d7cba45c-9e16-4f7f-b85a-e5e45b38127f\",\n",
      "    \"image\": \"xmlab506/source.jpg\",\n",
      "    \"conversations\": [\n",
      "        {\n",
      "            \"from\": \"human\",\n",
      "            \"value\": \"<image>\\n\\u56fe\\u7247\\u4e2d\\u5927\\u8111\\u5de6\\u4fa7\\u7684\\u75be\\u75c5\\u4f1a\\u7ed9\\u60a3\\u8005\\u5e26\\u6765\\u4ec0\\u4e48\\u6837\\u7684\\u75c7\\u72b6?\"\n",
      "        },\n",
      "        {\n",
      "            \"from\": \"gpt\",\n",
      "            \"value\": \"\\u89c6\\u529b\\u969c\\u788d,\\u5455\\u5410,\\u8033\\u9e23,\\u9885\\u5185\\u538b\\u589e\\u9ad8\"\n",
      "        }\n",
      "    ],\n",
      "    \"detection\": [\n",
      "        {\n",
      "            \"Brain Edema\": [\n",
      "                126.0,\n",
      "                102.0,\n",
      "                56.0,\n",
      "                99.0\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"Brain Non-enhancing Tumor\": [\n",
      "                140.0,\n",
      "                145.0,\n",
      "                9.0,\n",
      "                13.0\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"Brain Enhancing Tumor\": [\n",
      "                128.0,\n",
      "                113.0,\n",
      "                30.0,\n",
      "                55.0\n",
      "            ]\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "# Path to the final transformed train.json file\n",
    "final_train_json_path = '/Users/jeffreysherer/Desktop/Dissertation/Slake1.0/augmented/final_train.json'\n",
    "\n",
    "# Load the final transformed train.json file\n",
    "with open(final_train_json_path, 'r') as file:\n",
    "    transformed_data = json.load(file)\n",
    "\n",
    "# Randomly sample 5 entries from the dataset to inspect\n",
    "sampled_entries = random.sample(transformed_data, 5)\n",
    "\n",
    "# Print the sampled entries\n",
    "for entry in sampled_entries:\n",
    "    print(json.dumps(entry, indent=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now doing the trst adn validate json files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"id\": \"29a5c627-dfa3-4e30-ab3c-c088a78b9a7a\",\n",
      "        \"image\": \"xmlab0/source.jpg\",\n",
      "        \"conversations\": [\n",
      "            {\n",
      "                \"from\": \"human\",\n",
      "                \"value\": \"<image>\\nWhat modality is used to take this image?\"\n",
      "            },\n",
      "            {\n",
      "                \"from\": \"gpt\",\n",
      "                \"value\": \"MRI\"\n",
      "            }\n",
      "        ],\n",
      "        \"detection\": [\n",
      "            {\n",
      "                \"Liver\": [\n",
      "                    33.0,\n",
      "                    67.0,\n",
      "                    98.0,\n",
      "                    108.0\n",
      "                ]\n",
      "            },\n",
      "            {\n",
      "                \"Left Kidney\": [\n",
      "                    148.0,\n",
      "                    142.0,\n",
      "                    46.0,\n",
      "                    32.0\n",
      "                ]\n",
      "            },\n",
      "            {\n",
      "                \"Right Kidney\": [\n",
      "                    65.0,\n",
      "                    138.0,\n",
      "                    41.0,\n",
      "                    37.0\n",
      "                ]\n",
      "            },\n",
      "            {\n",
      "                \"Spleen\": [\n",
      "                    197.0,\n",
      "                    118.0,\n",
      "                    21.0,\n",
      "                    47.0\n",
      "                ]\n",
      "            }\n",
      "        ]\n",
      "    },\n",
      "    {\n",
      "        \"id\": \"f40cd97d-de23-43de-8e36-7e0b1f7e3376\",\n",
      "        \"image\": \"xmlab0/source.jpg\",\n",
      "        \"conversations\": [\n",
      "            {\n",
      "                \"from\": \"human\",\n",
      "                \"value\": \"<image>\\nWhich part of the body does this image belong to?\"\n",
      "            },\n",
      "            {\n",
      "                \"from\": \"gpt\",\n",
      "                \"value\": \"Abdomen\"\n",
      "            }\n",
      "        ],\n",
      "        \"detection\": [\n",
      "            {\n",
      "                \"Liver\": [\n",
      "                    33.0,\n",
      "                    67.0,\n",
      "                    98.0,\n",
      "                    108.0\n",
      "                ]\n",
      "            },\n",
      "            {\n",
      "                \"Left Kidney\": [\n",
      "                    148.0,\n",
      "                    142.0,\n",
      "                    46.0,\n",
      "                    32.0\n",
      "                ]\n",
      "            },\n",
      "            {\n",
      "                \"Right Kidney\": [\n",
      "                    65.0,\n",
      "                    138.0,\n",
      "                    41.0,\n",
      "                    37.0\n",
      "                ]\n",
      "            },\n",
      "            {\n",
      "                \"Spleen\": [\n",
      "                    197.0,\n",
      "                    118.0,\n",
      "                    21.0,\n",
      "                    47.0\n",
      "                ]\n",
      "            }\n",
      "        ]\n",
      "    },\n",
      "    {\n",
      "        \"id\": \"ba931e16-83e4-4e03-b127-c4418bedbd20\",\n",
      "        \"image\": \"xmlab0/source.jpg\",\n",
      "        \"conversations\": [\n",
      "            {\n",
      "                \"from\": \"human\",\n",
      "                \"value\": \"<image>\\nWhat is the mr weighting in this image?\"\n",
      "            },\n",
      "            {\n",
      "                \"from\": \"gpt\",\n",
      "                \"value\": \"T2\"\n",
      "            }\n",
      "        ],\n",
      "        \"detection\": [\n",
      "            {\n",
      "                \"Liver\": [\n",
      "                    33.0,\n",
      "                    67.0,\n",
      "                    98.0,\n",
      "                    108.0\n",
      "                ]\n",
      "            },\n",
      "            {\n",
      "                \"Left Kidney\": [\n",
      "                    148.0,\n",
      "                    142.0,\n",
      "                    46.0,\n",
      "                    32.0\n",
      "                ]\n",
      "            },\n",
      "            {\n",
      "                \"Right Kidney\": [\n",
      "                    65.0,\n",
      "                    138.0,\n",
      "                    41.0,\n",
      "                    37.0\n",
      "                ]\n",
      "            },\n",
      "            {\n",
      "                \"Spleen\": [\n",
      "                    197.0,\n",
      "                    118.0,\n",
      "                    21.0,\n",
      "                    47.0\n",
      "                ]\n",
      "            }\n",
      "        ]\n",
      "    }\n",
      "]\n",
      "[\n",
      "    {\n",
      "        \"id\": \"1324e8cc-006b-4679-8a84-be3e37a007ac\",\n",
      "        \"image\": \"xmlab102/source.jpg\",\n",
      "        \"conversations\": [\n",
      "            {\n",
      "                \"from\": \"human\",\n",
      "                \"value\": \"<image>\\nWhat modality is used to take this image?\"\n",
      "            },\n",
      "            {\n",
      "                \"from\": \"gpt\",\n",
      "                \"value\": \"CT\"\n",
      "            }\n",
      "        ],\n",
      "        \"detection\": [\n",
      "            {\n",
      "                \"Lung Cancer\": [\n",
      "                    289.0,\n",
      "                    301.0,\n",
      "                    17.0,\n",
      "                    22.0\n",
      "                ]\n",
      "            }\n",
      "        ]\n",
      "    },\n",
      "    {\n",
      "        \"id\": \"bdd9165e-3a51-4f69-aa1d-8f544eff2ea8\",\n",
      "        \"image\": \"xmlab102/source.jpg\",\n",
      "        \"conversations\": [\n",
      "            {\n",
      "                \"from\": \"human\",\n",
      "                \"value\": \"<image>\\nWhich part of the body does this image belong to?\"\n",
      "            },\n",
      "            {\n",
      "                \"from\": \"gpt\",\n",
      "                \"value\": \"Chest\"\n",
      "            }\n",
      "        ],\n",
      "        \"detection\": [\n",
      "            {\n",
      "                \"Lung Cancer\": [\n",
      "                    289.0,\n",
      "                    301.0,\n",
      "                    17.0,\n",
      "                    22.0\n",
      "                ]\n",
      "            }\n",
      "        ]\n",
      "    },\n",
      "    {\n",
      "        \"id\": \"22e9f48b-35e2-43a9-88cd-140bcfbd060e\",\n",
      "        \"image\": \"xmlab102/source.jpg\",\n",
      "        \"conversations\": [\n",
      "            {\n",
      "                \"from\": \"human\",\n",
      "                \"value\": \"<image>\\nWhat is the main organ in the image?\"\n",
      "            },\n",
      "            {\n",
      "                \"from\": \"gpt\",\n",
      "                \"value\": \"Lung, Spinal Cord\"\n",
      "            }\n",
      "        ],\n",
      "        \"detection\": [\n",
      "            {\n",
      "                \"Lung Cancer\": [\n",
      "                    289.0,\n",
      "                    301.0,\n",
      "                    17.0,\n",
      "                    22.0\n",
      "                ]\n",
      "            }\n",
      "        ]\n",
      "    }\n",
      "]\n",
      "Final validate.json has been saved to /Users/jeffreysherer/Desktop/Dissertation/Slake1.0/augmented/final_validate.json\n",
      "Final test.json has been saved to /Users/jeffreysherer/Desktop/Dissertation/Slake1.0/augmented/final_test.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import uuid  # To generate unique IDs\n",
    "import os\n",
    "\n",
    "# Paths to the original validate.json and test.json files\n",
    "validate_json_path = '/Users/jeffreysherer/Desktop/Dissertation/Slake1.0/validate.json'\n",
    "test_json_path = '/Users/jeffreysherer/Desktop/Dissertation/Slake1.0/test.json'\n",
    "\n",
    "# Directory containing the image folders with detection.json files\n",
    "image_directory = '/Users/jeffreysherer/Dissertation/data/imgs-1'\n",
    "\n",
    "# Load the validate.json file\n",
    "with open(validate_json_path, 'r') as file:\n",
    "    validate_data = json.load(file)\n",
    "\n",
    "# Load the test.json file\n",
    "with open(test_json_path, 'r') as file:\n",
    "    test_data = json.load(file)\n",
    "\n",
    "# Function to update the data with bounding box coordinates\n",
    "def update_data_with_bounding_boxes(data):\n",
    "    for entry in data:\n",
    "        img_folder = os.path.dirname(entry['img_name'])\n",
    "        detection_json_path = os.path.join(image_directory, img_folder, 'detection.json')\n",
    "\n",
    "        if os.path.exists(detection_json_path):\n",
    "            with open(detection_json_path, 'r') as file:\n",
    "                detection_data = json.load(file)\n",
    "            entry['detection'] = detection_data\n",
    "\n",
    "    return data\n",
    "\n",
    "# Function to transform the data to the required format\n",
    "def transform_data(data):\n",
    "    transformed_data = []\n",
    "    for entry in data:\n",
    "        unique_id = str(uuid.uuid4())  # Generate a unique ID for each entry\n",
    "        img_path = entry['img_name']  # Use the img_name as the image path\n",
    "        question = entry['question']\n",
    "        answer = entry['answer']\n",
    "        \n",
    "        transformed_entry = {\n",
    "            \"id\": unique_id,\n",
    "            \"image\": img_path,\n",
    "            \"conversations\": [\n",
    "                {\n",
    "                    \"from\": \"human\",\n",
    "                    \"value\": f\"<image>\\n{question}\"\n",
    "                },\n",
    "                {\n",
    "                    \"from\": \"gpt\",\n",
    "                    \"value\": answer\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "        if 'detection' in entry:\n",
    "            transformed_entry['detection'] = entry['detection']\n",
    "        transformed_data.append(transformed_entry)\n",
    "    return transformed_data\n",
    "\n",
    "# Update validate and test data with bounding box coordinates\n",
    "updated_validate_data = update_data_with_bounding_boxes(validate_data)\n",
    "updated_test_data = update_data_with_bounding_boxes(test_data)\n",
    "\n",
    "# Transform validate and test data\n",
    "transformed_validate_data = transform_data(updated_validate_data)\n",
    "transformed_test_data = transform_data(updated_test_data)\n",
    "\n",
    "# Display the first few entries to verify the content\n",
    "print(json.dumps(transformed_validate_data[:3], indent=4))  # Adjust the number of entries to display based on your need\n",
    "print(json.dumps(transformed_test_data[:3], indent=4))  # Adjust the number of entries to display based on your need\n",
    "\n",
    "# Paths to save the final transformed JSON files\n",
    "final_validate_json_path = '/Users/jeffreysherer/Desktop/Dissertation/Slake1.0/augmented/final_validate.json'\n",
    "final_test_json_path = '/Users/jeffreysherer/Desktop/Dissertation/Slake1.0/augmented/final_test.json'\n",
    "\n",
    "# Write the transformed validate data to a new JSON file\n",
    "with open(final_validate_json_path, 'w') as file:\n",
    "    json.dump(transformed_validate_data, file, indent=4)\n",
    "\n",
    "# Write the transformed test data to a new JSON file\n",
    "with open(final_test_json_path, 'w') as file:\n",
    "    json.dump(transformed_test_data, file, indent=4)\n",
    "\n",
    "print(\"Final validate.json has been saved to\", final_validate_json_path)\n",
    "print(\"Final test.json has been saved to\", final_test_json_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"id\": \"4dd4703e-2e6f-4b98-aef4-69e4bd3adf0e\",\n",
      "        \"image\": \"xmlab0/source.jpg\",\n",
      "        \"conversations\": [\n",
      "            {\n",
      "                \"from\": \"human\",\n",
      "                \"value\": \"<image>\\nWhat modality is used to take this image?\"\n",
      "            },\n",
      "            {\n",
      "                \"from\": \"gpt\",\n",
      "                \"value\": \"MRI\"\n",
      "            }\n",
      "        ],\n",
      "        \"detection\": [\n",
      "            {\n",
      "                \"Liver\": [\n",
      "                    33.0,\n",
      "                    67.0,\n",
      "                    98.0,\n",
      "                    108.0\n",
      "                ]\n",
      "            },\n",
      "            {\n",
      "                \"Left Kidney\": [\n",
      "                    148.0,\n",
      "                    142.0,\n",
      "                    46.0,\n",
      "                    32.0\n",
      "                ]\n",
      "            },\n",
      "            {\n",
      "                \"Right Kidney\": [\n",
      "                    65.0,\n",
      "                    138.0,\n",
      "                    41.0,\n",
      "                    37.0\n",
      "                ]\n",
      "            },\n",
      "            {\n",
      "                \"Spleen\": [\n",
      "                    197.0,\n",
      "                    118.0,\n",
      "                    21.0,\n",
      "                    47.0\n",
      "                ]\n",
      "            }\n",
      "        ]\n",
      "    },\n",
      "    {\n",
      "        \"id\": \"d3505b5e-6cef-4d6e-9513-afd82ef1737c\",\n",
      "        \"image\": \"xmlab0/source.jpg\",\n",
      "        \"conversations\": [\n",
      "            {\n",
      "                \"from\": \"human\",\n",
      "                \"value\": \"<image>\\nWhich part of the body does this image belong to?\"\n",
      "            },\n",
      "            {\n",
      "                \"from\": \"gpt\",\n",
      "                \"value\": \"Abdomen\"\n",
      "            }\n",
      "        ],\n",
      "        \"detection\": [\n",
      "            {\n",
      "                \"Liver\": [\n",
      "                    33.0,\n",
      "                    67.0,\n",
      "                    98.0,\n",
      "                    108.0\n",
      "                ]\n",
      "            },\n",
      "            {\n",
      "                \"Left Kidney\": [\n",
      "                    148.0,\n",
      "                    142.0,\n",
      "                    46.0,\n",
      "                    32.0\n",
      "                ]\n",
      "            },\n",
      "            {\n",
      "                \"Right Kidney\": [\n",
      "                    65.0,\n",
      "                    138.0,\n",
      "                    41.0,\n",
      "                    37.0\n",
      "                ]\n",
      "            },\n",
      "            {\n",
      "                \"Spleen\": [\n",
      "                    197.0,\n",
      "                    118.0,\n",
      "                    21.0,\n",
      "                    47.0\n",
      "                ]\n",
      "            }\n",
      "        ]\n",
      "    },\n",
      "    {\n",
      "        \"id\": \"6d9a4a61-47d3-4311-8f23-ee2cb64173cd\",\n",
      "        \"image\": \"xmlab0/source.jpg\",\n",
      "        \"conversations\": [\n",
      "            {\n",
      "                \"from\": \"human\",\n",
      "                \"value\": \"<image>\\nWhat is the mr weighting in this image?\"\n",
      "            },\n",
      "            {\n",
      "                \"from\": \"gpt\",\n",
      "                \"value\": \"T2\"\n",
      "            }\n",
      "        ],\n",
      "        \"detection\": [\n",
      "            {\n",
      "                \"Liver\": [\n",
      "                    33.0,\n",
      "                    67.0,\n",
      "                    98.0,\n",
      "                    108.0\n",
      "                ]\n",
      "            },\n",
      "            {\n",
      "                \"Left Kidney\": [\n",
      "                    148.0,\n",
      "                    142.0,\n",
      "                    46.0,\n",
      "                    32.0\n",
      "                ]\n",
      "            },\n",
      "            {\n",
      "                \"Right Kidney\": [\n",
      "                    65.0,\n",
      "                    138.0,\n",
      "                    41.0,\n",
      "                    37.0\n",
      "                ]\n",
      "            },\n",
      "            {\n",
      "                \"Spleen\": [\n",
      "                    197.0,\n",
      "                    118.0,\n",
      "                    21.0,\n",
      "                    47.0\n",
      "                ]\n",
      "            }\n",
      "        ]\n",
      "    }\n",
      "]\n",
      "[\n",
      "    {\n",
      "        \"id\": \"381fbe40-4ed9-48a9-be53-439082311ce3\",\n",
      "        \"image\": \"xmlab102/source.jpg\",\n",
      "        \"conversations\": [\n",
      "            {\n",
      "                \"from\": \"human\",\n",
      "                \"value\": \"<image>\\nWhat modality is used to take this image?\"\n",
      "            },\n",
      "            {\n",
      "                \"from\": \"gpt\",\n",
      "                \"value\": \"CT\"\n",
      "            }\n",
      "        ],\n",
      "        \"detection\": [\n",
      "            {\n",
      "                \"Lung Cancer\": [\n",
      "                    289.0,\n",
      "                    301.0,\n",
      "                    17.0,\n",
      "                    22.0\n",
      "                ]\n",
      "            }\n",
      "        ]\n",
      "    },\n",
      "    {\n",
      "        \"id\": \"6b9e4eeb-2f78-4ba5-9dea-428654bfb4f0\",\n",
      "        \"image\": \"xmlab102/source.jpg\",\n",
      "        \"conversations\": [\n",
      "            {\n",
      "                \"from\": \"human\",\n",
      "                \"value\": \"<image>\\nWhich part of the body does this image belong to?\"\n",
      "            },\n",
      "            {\n",
      "                \"from\": \"gpt\",\n",
      "                \"value\": \"Chest\"\n",
      "            }\n",
      "        ],\n",
      "        \"detection\": [\n",
      "            {\n",
      "                \"Lung Cancer\": [\n",
      "                    289.0,\n",
      "                    301.0,\n",
      "                    17.0,\n",
      "                    22.0\n",
      "                ]\n",
      "            }\n",
      "        ]\n",
      "    },\n",
      "    {\n",
      "        \"id\": \"bf8cb3b0-64f8-4d66-a3df-a63a534c6897\",\n",
      "        \"image\": \"xmlab102/source.jpg\",\n",
      "        \"conversations\": [\n",
      "            {\n",
      "                \"from\": \"human\",\n",
      "                \"value\": \"<image>\\nWhat is the main organ in the image?\"\n",
      "            },\n",
      "            {\n",
      "                \"from\": \"gpt\",\n",
      "                \"value\": \"Lung, Spinal Cord\"\n",
      "            }\n",
      "        ],\n",
      "        \"detection\": [\n",
      "            {\n",
      "                \"Lung Cancer\": [\n",
      "                    289.0,\n",
      "                    301.0,\n",
      "                    17.0,\n",
      "                    22.0\n",
      "                ]\n",
      "            }\n",
      "        ]\n",
      "    }\n",
      "]\n",
      "Final validate.json has been saved to /Users/jeffreysherer/Desktop/Dissertation/Slake1.0/augmented/final_validate.json\n",
      "Final test.json has been saved to /Users/jeffreysherer/Desktop/Dissertation/Slake1.0/augmented/final_test.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import uuid  # To generate unique IDs\n",
    "\n",
    "# Paths to the original validate.json and test.json files\n",
    "validate_json_path = '/Users/jeffreysherer/Desktop/Dissertation/Slake1.0/validate.json'\n",
    "test_json_path = '/Users/jeffreysherer/Desktop/Dissertation/Slake1.0/test.json'\n",
    "\n",
    "# Directory containing the image folders with detection.json files\n",
    "image_directory = '/Users/jeffreysherer/Dissertation/data/imgs-1'\n",
    "\n",
    "# Load the validate.json file\n",
    "with open(validate_json_path, 'r') as file:\n",
    "    validate_data = json.load(file)\n",
    "\n",
    "# Load the test.json file\n",
    "with open(test_json_path, 'r') as file:\n",
    "    test_data = json.load(file)\n",
    "\n",
    "# Function to update and transform the data with bounding box coordinates\n",
    "def transform_data_with_bounding_boxes(data):\n",
    "    transformed_data = []\n",
    "    for entry in data:\n",
    "        unique_id = str(uuid.uuid4())  # Generate a unique ID for each entry\n",
    "        img_path = entry['img_name']  # Use the img_name as the image path\n",
    "        question = entry['question']\n",
    "        answer = entry['answer']\n",
    "\n",
    "        # Extract the folder name from img_name to locate detection.json\n",
    "        img_folder = os.path.dirname(img_path)\n",
    "        detection_json_path = os.path.join(image_directory, img_folder, 'detection.json')\n",
    "        \n",
    "        # Load detection data if it exists\n",
    "        detection_data = None\n",
    "        if os.path.exists(detection_json_path):\n",
    "            with open(detection_json_path, 'r') as file:\n",
    "                detection_data = json.load(file)\n",
    "        \n",
    "        transformed_entry = {\n",
    "            \"id\": unique_id,\n",
    "            \"image\": img_path,\n",
    "            \"conversations\": [\n",
    "                {\n",
    "                    \"from\": \"human\",\n",
    "                    \"value\": f\"<image>\\n{question}\"\n",
    "                },\n",
    "                {\n",
    "                    \"from\": \"gpt\",\n",
    "                    \"value\": answer\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        if detection_data:\n",
    "            transformed_entry['detection'] = detection_data\n",
    "        \n",
    "        transformed_data.append(transformed_entry)\n",
    "    \n",
    "    return transformed_data\n",
    "\n",
    "# Transform validate and test data\n",
    "transformed_validate_data = transform_data_with_bounding_boxes(validate_data)\n",
    "transformed_test_data = transform_data_with_bounding_boxes(test_data)\n",
    "\n",
    "# Display the first few entries to verify the content\n",
    "print(json.dumps(transformed_validate_data[:3], indent=4))  # Adjust the number of entries to display based on your need\n",
    "print(json.dumps(transformed_test_data[:3], indent=4))  # Adjust the number of entries to display based on your need\n",
    "\n",
    "# Paths to save the final transformed JSON files\n",
    "final_validate_json_path = '/Users/jeffreysherer/Desktop/Dissertation/Slake1.0/augmented/final_validate.json'\n",
    "final_test_json_path = '/Users/jeffreysherer/Desktop/Dissertation/Slake1.0/augmented/final_test.json'\n",
    "\n",
    "# Write the transformed validate data to a new JSON file\n",
    "with open(final_validate_json_path, 'w') as file:\n",
    "    json.dump(transformed_validate_data, file, indent=4)\n",
    "\n",
    "# Write the transformed test data to a new JSON file\n",
    "with open(final_test_json_path, 'w') as file:\n",
    "    json.dump(transformed_test_data, file, indent=4)\n",
    "\n",
    "print(\"Final validate.json has been saved to\", final_validate_json_path)\n",
    "print(\"Final test.json has been saved to\", final_test_json_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated validate.json has been saved to /Users/jeffreysherer/Desktop/Dissertation/Slake1.0/augmented/BBF_validate.json\n",
      "Updated test.json has been saved to /Users/jeffreysherer/Desktop/Dissertation/Slake1.0/augmented/BBF_test.json\n"
     ]
    }
   ],
   "source": [
    "# Paths to save the updated validate and test JSON files\n",
    "augmented_folder = '/Users/jeffreysherer/Desktop/Dissertation/Slake1.0/augmented'\n",
    "updated_validate_json_path = os.path.join(augmented_folder, 'BBF_validate.json')\n",
    "updated_test_json_path = os.path.join(augmented_folder, 'BBF_test.json')\n",
    "\n",
    "# Ensure the augmented folder exists\n",
    "os.makedirs(augmented_folder, exist_ok=True)\n",
    "\n",
    "# Write the updated validate data to a new JSON file\n",
    "with open(updated_validate_json_path, 'w') as file:\n",
    "    json.dump(updated_validate_data, file, indent=4)\n",
    "\n",
    "# Write the updated test data to a new JSON file\n",
    "with open(updated_test_json_path, 'w') as file:\n",
    "    json.dump(updated_test_data, file, indent=4)\n",
    "\n",
    "print(\"Updated validate.json has been saved to\", updated_validate_json_path)\n",
    "print(\"Updated test.json has been saved to\", updated_test_json_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BBL_train.json has been saved to /Users/jeffreysherer/Desktop/Dissertation/Slake1.0/augmented/BBL_train.json\n",
      "BBL_validate.json has been saved to /Users/jeffreysherer/Desktop/Dissertation/Slake1.0/augmented/BBL_validate.json\n",
      "BBL_test.json has been saved to /Users/jeffreysherer/Desktop/Dissertation/Slake1.0/augmented/BBL_test.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import uuid  # To generate unique IDs\n",
    "\n",
    "# Function to transform the data with detection coordinates after the answer\n",
    "def transform_data_with_bounding_boxes_last(data):\n",
    "    transformed_data = []\n",
    "    for entry in data:\n",
    "        unique_id = str(uuid.uuid4())  # Generate a unique ID for each entry\n",
    "        img_path = entry['img_name']  # Use the img_name as the image path\n",
    "        question = entry['question']\n",
    "        answer = entry['answer']\n",
    "\n",
    "        # Extract the folder name from img_name to locate detection.json\n",
    "        img_folder = os.path.dirname(img_path)\n",
    "        detection_json_path = os.path.join(image_directory, img_folder, 'detection.json')\n",
    "        \n",
    "        # Load detection data if it exists\n",
    "        detection_data = None\n",
    "        if os.path.exists(detection_json_path):\n",
    "            with open(detection_json_path, 'r') as file:\n",
    "                detection_data = json.load(file)\n",
    "        \n",
    "        transformed_entry = {\n",
    "            \"id\": unique_id,\n",
    "            \"image\": img_path,\n",
    "            \"conversations\": [\n",
    "                {\n",
    "                    \"from\": \"human\",\n",
    "                    \"value\": f\"<image>\\n{question}\"\n",
    "                },\n",
    "                {\n",
    "                    \"from\": \"gpt\",\n",
    "                    \"value\": answer\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "\n",
    "        # Add detection data after the answer\n",
    "        if detection_data:\n",
    "            transformed_entry['detection'] = detection_data\n",
    "        \n",
    "        transformed_data.append(transformed_entry)\n",
    "    \n",
    "    return transformed_data\n",
    "\n",
    "# Transform the train, validate, and test data with detection coordinates last\n",
    "transformed_train_data_bbl = transform_data_with_bounding_boxes_last(updated_train_data)\n",
    "transformed_validate_data_bbl = transform_data_with_bounding_boxes_last(updated_validate_data)\n",
    "transformed_test_data_bbl = transform_data_with_bounding_boxes_last(updated_test_data)\n",
    "\n",
    "# Paths to save the final BBL JSON files\n",
    "final_train_json_path_bbl = os.path.join(augmented_dir, 'BBL_train.json')\n",
    "final_validate_json_path_bbl = os.path.join(augmented_dir, 'BBL_validate.json')\n",
    "final_test_json_path_bbl = os.path.join(augmented_dir, 'BBL_test.json')\n",
    "\n",
    "# Write the transformed train data with detection coordinates last to a new JSON file\n",
    "with open(final_train_json_path_bbl, 'w') as file:\n",
    "    json.dump(transformed_train_data_bbl, file, indent=4)\n",
    "\n",
    "# Write the transformed validate data with detection coordinates last to a new JSON file\n",
    "with open(final_validate_json_path_bbl, 'w') as file:\n",
    "    json.dump(transformed_validate_data_bbl, file, indent=4)\n",
    "\n",
    "# Write the transformed test data with detection coordinates last to a new JSON file\n",
    "with open(final_test_json_path_bbl, 'w') as file:\n",
    "    json.dump(transformed_test_data_bbl, file, indent=4)\n",
    "\n",
    "print(\"BBL_train.json has been saved to\", final_train_json_path_bbl)\n",
    "print(\"BBL_validate.json has been saved to\", final_validate_json_path_bbl)\n",
    "print(\"BBL_test.json has been saved to\", final_test_json_path_bbl)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
