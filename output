THESE ARE THE .ERR AND .OUT BEFORE I DECIDED TO REDO MY CONDA ENVIRONMENT

[jjls2000@login1 [dmog] Dissertation]$ cat llava-med-test-86076.err
/users/jjls2000/.conda/envs/llavamed_new/lib/python3.10/site-packages/transformers/utils/generic.py:482: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.
  _torch_pytree._register_pytree_node(
/users/jjls2000/.conda/envs/llavamed_new/lib/python3.10/site-packages/transformers/utils/generic.py:339: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.
  _torch_pytree._register_pytree_node(
/users/jjls2000/.conda/envs/llavamed_new/lib/python3.10/site-packages/transformers/utils/generic.py:339: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.
  _torch_pytree._register_pytree_node(
/users/jjls2000/.conda/envs/llavamed_new/lib/python3.10/site-packages/transformers/utils/generic.py:482: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.
  _torch_pytree._register_pytree_node(
/users/jjls2000/.conda/envs/llavamed_new/lib/python3.10/site-packages/transformers/utils/generic.py:339: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.
  _torch_pytree._register_pytree_node(
/users/jjls2000/.conda/envs/llavamed_new/lib/python3.10/site-packages/transformers/utils/generic.py:339: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.
  _torch_pytree._register_pytree_node(
/users/jjls2000/.conda/envs/llavamed_new/lib/python3.10/site-packages/transformers/utils/generic.py:482: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.
  _torch_pytree._register_pytree_node(
/users/jjls2000/.conda/envs/llavamed_new/lib/python3.10/site-packages/transformers/utils/generic.py:339: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.
  _torch_pytree._register_pytree_node(
/users/jjls2000/.conda/envs/llavamed_new/lib/python3.10/site-packages/transformers/utils/generic.py:339: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.
  _torch_pytree._register_pytree_node(
/users/jjls2000/.conda/envs/llavamed_new/lib/python3.10/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead
  warnings.warn(
You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:27<00:00, 13.70s/it]
[rank0]: Traceback (most recent call last):
[rank0]:   File "/users/jjls2000/sharedscratch/Dissertation/llava/train/train_mem.py", line 4, in <module>
[rank0]:     train(attn_implementation="flash_attention_2")
[rank0]:   File "/mnt/scratch/users/jjls2000/Dissertation/llava/train/train.py", line 911, in train
[rank0]:     model.get_model().initialize_vision_modules(
[rank0]:   File "/mnt/scratch/users/jjls2000/Dissertation/llava/model/llava_arch.py", line 93, in initialize_vision_modules
[rank0]:     mm_projector_weights = torch.load(pretrain_mm_mlp_adapter, map_location='cpu')
[rank0]:   File "/users/jjls2000/.conda/envs/llavamed_new/lib/python3.10/site-packages/torch/serialization.py", line 1040, in load
[rank0]:     return _legacy_load(opened_file, map_location, pickle_module, **pickle_load_args)
[rank0]:   File "/users/jjls2000/.conda/envs/llavamed_new/lib/python3.10/site-packages/torch/serialization.py", line 1262, in _legacy_load
[rank0]:     magic_number = pickle_module.load(f, **pickle_load_args)
[rank0]: _pickle.UnpicklingError: A load persistent id instruction was encountered,
[rank0]: but no persistent_load function was specified.


.OUT FILE BEFORE I REDID THE CONDA ENVIRONMENT


(base) [jjls2000@login1 [dmog] Dissertation]$ cat llava-med-test-86076.out
CUDA_HOME is set to: /opt/gridware/depots/761a7df9/el9/pkg/libs/nvidia-cuda/11.8.0
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2022 NVIDIA Corporation
Built on Wed_Sep_21_10:33:58_PDT_2022
Cuda compilation tools, release 11.8, V11.8.89
Build cuda_11.8.r11.8/compiler.31833905_0
CUDA available: False
[2024-07-09 20:43:51,017] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-07-09 20:43:57,945] [WARNING] [runner.py:202:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
Detected CUDA_VISIBLE_DEVICES=0: setting --include=localhost:0
[2024-07-09 20:43:57,952] [INFO] [runner.py:571:main] cmd = /users/jjls2000/.conda/envs/llavamed_new/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMF19 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None /users/jjls2000/sharedscratch/Dissertation/llava/train/train_mem.py --lora_enable True --lora_r 128 --lora_alpha 256 --mm_projector_lr 2e-5 --deepspeed /users/jjls2000/sharedscratch/Dissertation/scripts/zero3.json --model_name_or_path /users/jjls2000/sharedscratch/Dissertation/checkpoints/llava-v1.5-7b --version llava_v1.5 --data_path /users/jjls2000/sharedscratch/Dissertation/Slake1.0/augmented/BBF_train.json --image_folder /users/jjls2000/sharedscratch/Dissertation/data/imgs-1 --vision_tower openai/clip-vit-large-patch14-336 --pretrain_mm_mlp_adapter /users/jjls2000/sharedscratch/Dissertation/checkpoints/llava-v1.5-7b/mm_projector_extracted/mm_projector/data.pkl --mm_projector_type mlp2x_gelu --mm_vision_select_layer -2 --mm_use_im_start_end False --mm_use_im_patch_token False --image_aspect_ratio pad --group_by_modality_length True --bf16 True --output_dir /users/jjls2000/sharedscratch/Dissertation/results/20240709_204345 --num_train_epochs 1 --per_device_train_batch_size 16 --per_device_eval_batch_size 4 --gradient_accumulation_steps 1 --evaluation_strategy no --save_strategy steps --save_steps 50000 --save_total_limit 1 --learning_rate 2e-4 --weight_decay 0. --warmup_ratio 0.03 --lr_scheduler_type cosine --logging_steps 1 --tf32 True --model_max_length 2048 --gradient_checkpointing True --lazy_preprocess True --report_to wandb
[2024-07-09 20:43:59,110] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-07-09 20:43:59,974] [INFO] [launch.py:145:main] WORLD INFO DICT: {'localhost': [0]}
[2024-07-09 20:43:59,974] [INFO] [launch.py:151:main] nnodes=1, num_local_procs=1, node_rank=0
[2024-07-09 20:43:59,974] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})
[2024-07-09 20:43:59,974] [INFO] [launch.py:163:main] dist_world_size=1
[2024-07-09 20:43:59,974] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0
[2024-07-09 20:44:05,172] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-07-09 20:44:05,386] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-07-09 20:44:05,386] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2024-07-09 20:44:06,230] [INFO] [partition_parameters.py:348:__exit__] finished initializing model - num_params = 295, num_elems = 6.76B
Adding LoRA adapters...
[2024-07-09 20:44:37,306] [INFO] [partition_parameters.py:348:__exit__] finished initializing model - num_params = 686, num_elems = 7.06B
[2024-07-09 20:44:39,014] [INFO] [launch.py:315:sigkill_handler] Killing subprocess 861011
[2024-07-09 20:44:39,014] [ERROR] [launch.py:321:sigkill_handler] ['/users/jjls2000/.conda/envs/llavamed_new/bin/python', '-u', '/users/jjls2000/sharedscratch/Dissertation/llava/train/train_mem.py', '--local_rank=0', '--lora_enable', 'True', '--lora_r', '128', '--lora_alpha', '256', '--mm_projector_lr', '2e-5', '--deepspeed', '/users/jjls2000/sharedscratch/Dissertation/scripts/zero3.json', '--model_name_or_path', '/users/jjls2000/sharedscratch/Dissertation/checkpoints/llava-v1.5-7b', '--version', 'llava_v1.5', '--data_path', '/users/jjls2000/sharedscratch/Dissertation/Slake1.0/augmented/BBF_train.json', '--image_folder', '/users/jjls2000/sharedscratch/Dissertation/data/imgs-1', '--vision_tower', 'openai/clip-vit-large-patch14-336', '--pretrain_mm_mlp_adapter', '/users/jjls2000/sharedscratch/Dissertation/checkpoints/llava-v1.5-7b/mm_projector_extracted/mm_projector/data.pkl', '--mm_projector_type', 'mlp2x_gelu', '--mm_vision_select_layer', '-2', '--mm_use_im_start_end', 'False', '--mm_use_im_patch_token', 'False', '--image_aspect_ratio', 'pad', '--group_by_modality_length', 'True', '--bf16', 'True', '--output_dir', '/users/jjls2000/sharedscratch/Dissertation/results/20240709_204345', '--num_train_epochs', '1', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--gradient_accumulation_steps', '1', '--evaluation_strategy', 'no', '--save_strategy', 'steps', '--save_steps', '50000', '--save_total_limit', '1', '--learning_rate', '2e-4', '--weight_decay', '0.', '--warmup_ratio', '0.03', '--lr_scheduler_type', 'cosine', '--logging_steps', '1', '--tf32', 'True', '--model_max_length', '2048', '--gradient_checkpointing', 'True', '--lazy_preprocess', 'True', '--report_to', 'wandb'] exits with return code = 1
Training completed for BBF dataset.
Training failed or output model not saved.







.ERR AND .OUT FILES FROM AFTER I TRIED TO REDO THE CONDA ENVIRONMENT (TRYING TO ACCOMEODATE THE LLAVA MED DEPENDENCIES)









(base) [jjls2000@login1 [dmog] Dissertation]$ cat llava-med-test-87550.err
Traceback (most recent call last):
  File "/users/jjls2000/sharedscratch/Dissertation/llava/train/train_mem.py", line 1, in <module>
    from llava.train.train import train
  File "/mnt/scratch/users/jjls2000/Dissertation/llava/__init__.py", line 1, in <module>
    from .model import LlavaLlamaForCausalLM
  File "/mnt/scratch/users/jjls2000/Dissertation/llava/model/__init__.py", line 2, in <module>
    from .language_model.llava_llama import LlavaLlamaForCausalLM, LlavaConfig
  File "/mnt/scratch/users/jjls2000/Dissertation/llava/model/language_model/llava_llama.py", line 21, in <module>
    from transformers import AutoConfig, AutoModelForCausalLM, \
  File "/users/jjls2000/.conda/envs/llava_med/lib/python3.10/site-packages/transformers/__init__.py", line 26, in <module>
    from . import dependency_versions_check
  File "/users/jjls2000/.conda/envs/llava_med/lib/python3.10/site-packages/transformers/dependency_versions_check.py", line 16, in <module>
    from .utils.versions import require_version, require_version_core
  File "/users/jjls2000/.conda/envs/llava_med/lib/python3.10/site-packages/transformers/utils/__init__.py", line 18, in <module>
    from huggingface_hub import get_full_repo_name  # for backward compatibility
ModuleNotFoundError: No module named 'huggingface_hub'


(base) [jjls2000@login1 [dmog] Dissertation]$ cat llava-med-test-87550.out
[2024-07-14 15:53:31,100] [WARNING] [real_accelerator.py:162:get_accelerator] Setting accelerator to CPU. If you have GPU or other accelerator, we were unable to detect it.
[2024-07-14 15:53:31,112] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cpu (auto detect)
[2024-07-14 15:53:31,698] [WARNING] [runner.py:202:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
Detected CUDA_VISIBLE_DEVICES=0: setting --include=localhost:0
[2024-07-14 15:53:31,702] [INFO] [runner.py:568:main] cmd = /users/jjls2000/.conda/envs/llava_med/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMF19 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None /users/jjls2000/sharedscratch/Dissertation/llava/train/train_mem.py --lora_enable True --lora_r 128 --lora_alpha 256 --mm_projector_lr 2e-5 --deepspeed /users/jjls2000/sharedscratch/Dissertation/scripts/zero3.json --model_name_or_path /users/jjls2000/sharedscratch/Dissertation/checkpoints/llava-v1.5-7b --version llava_v1.5 --data_path /users/jjls2000/sharedscratch/Dissertation/Slake1.0/augmented/BBF_train.json --image_folder /users/jjls2000/sharedscratch/Dissertation/data/imgs-1 --vision_tower openai/clip-vit-large-patch14-336 --pretrain_mm_mlp_adapter /users/jjls2000/sharedscratch/Dissertation/checkpoints/llava-v1.5-7b/mm_projector_extracted/mm_projector/data.pkl --mm_projector_type mlp2x_gelu --mm_vision_select_layer -2 --mm_use_im_start_end False --mm_use_im_patch_token False --image_aspect_ratio pad --group_by_modality_length True --bf16 True --output_dir /users/jjls2000/sharedscratch/Dissertation/results/20240709_214950 --num_train_epochs 1 --per_device_train_batch_size 16 --per_device_eval_batch_size 4 --gradient_accumulation_steps 1 --evaluation_strategy no --save_strategy steps --save_steps 50000 --save_total_limit 1 --learning_rate 2e-4 --weight_decay 0. --warmup_ratio 0.03 --lr_scheduler_type cosine --logging_steps 1 --tf32 True --model_max_length 2048 --gradient_checkpointing True --dataloader_num_workers 4 --lazy_preprocess True --report_to wandb
[2024-07-14 15:53:33,073] [WARNING] [real_accelerator.py:162:get_accelerator] Setting accelerator to CPU. If you have GPU or other accelerator, we were unable to detect it.
[2024-07-14 15:53:33,082] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cpu (auto detect)
[2024-07-14 15:53:33,506] [INFO] [launch.py:146:main] WORLD INFO DICT: {'localhost': [0]}
[2024-07-14 15:53:33,506] [INFO] [launch.py:152:main] nnodes=1, num_local_procs=1, node_rank=0
[2024-07-14 15:53:33,506] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})
[2024-07-14 15:53:33,506] [INFO] [launch.py:164:main] dist_world_size=1
[2024-07-14 15:53:33,506] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0
[2024-07-14 15:53:33,507] [INFO] [launch.py:256:main] process 3643517 spawned with command: ['/users/jjls2000/.conda/envs/llava_med/bin/python', '-u', '/users/jjls2000/sharedscratch/Dissertation/llava/train/train_mem.py', '--local_rank=0', '--lora_enable', 'True', '--lora_r', '128', '--lora_alpha', '256', '--mm_projector_lr', '2e-5', '--deepspeed', '/users/jjls2000/sharedscratch/Dissertation/scripts/zero3.json', '--model_name_or_path', '/users/jjls2000/sharedscratch/Dissertation/checkpoints/llava-v1.5-7b', '--version', 'llava_v1.5', '--data_path', '/users/jjls2000/sharedscratch/Dissertation/Slake1.0/augmented/BBF_train.json', '--image_folder', '/users/jjls2000/sharedscratch/Dissertation/data/imgs-1', '--vision_tower', 'openai/clip-vit-large-patch14-336', '--pretrain_mm_mlp_adapter', '/users/jjls2000/sharedscratch/Dissertation/checkpoints/llava-v1.5-7b/mm_projector_extracted/mm_projector/data.pkl', '--mm_projector_type', 'mlp2x_gelu', '--mm_vision_select_layer', '-2', '--mm_use_im_start_end', 'False', '--mm_use_im_patch_token', 'False', '--image_aspect_ratio', 'pad', '--group_by_modality_length', 'True', '--bf16', 'True', '--output_dir', '/users/jjls2000/sharedscratch/Dissertation/results/20240709_214950', '--num_train_epochs', '1', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--gradient_accumulation_steps', '1', '--evaluation_strategy', 'no', '--save_strategy', 'steps', '--save_steps', '50000', '--save_total_limit', '1', '--learning_rate', '2e-4', '--weight_decay', '0.', '--warmup_ratio', '0.03', '--lr_scheduler_type', 'cosine', '--logging_steps', '1', '--tf32', 'True', '--model_max_length', '2048', '--gradient_checkpointing', 'True', '--dataloader_num_workers', '4', '--lazy_preprocess', 'True', '--report_to', 'wandb']
Failed to import: No module named 'huggingface_hub'
[2024-07-14 15:53:35,508] [INFO] [launch.py:319:sigkill_handler] Killing subprocess 3643517
[2024-07-14 15:53:35,509] [ERROR] [launch.py:325:sigkill_handler] ['/users/jjls2000/.conda/envs/llava_med/bin/python', '-u', '/users/jjls2000/sharedscratch/Dissertation/llava/train/train_mem.py', '--local_rank=0', '--lora_enable', 'True', '--lora_r', '128', '--lora_alpha', '256', '--mm_projector_lr', '2e-5', '--deepspeed', '/users/jjls2000/sharedscratch/Dissertation/scripts/zero3.json', '--model_name_or_path', '/users/jjls2000/sharedscratch/Dissertation/checkpoints/llava-v1.5-7b', '--version', 'llava_v1.5', '--data_path', '/users/jjls2000/sharedscratch/Dissertation/Slake1.0/augmented/BBF_train.json', '--image_folder', '/users/jjls2000/sharedscratch/Dissertation/data/imgs-1', '--vision_tower', 'openai/clip-vit-large-patch14-336', '--pretrain_mm_mlp_adapter', '/users/jjls2000/sharedscratch/Dissertation/checkpoints/llava-v1.5-7b/mm_projector_extracted/mm_projector/data.pkl', '--mm_projector_type', 'mlp2x_gelu', '--mm_vision_select_layer', '-2', '--mm_use_im_start_end', 'False', '--mm_use_im_patch_token', 'False', '--image_aspect_ratio', 'pad', '--group_by_modality_length', 'True', '--bf16', 'True', '--output_dir', '/users/jjls2000/sharedscratch/Dissertation/results/20240709_214950', '--num_train_epochs', '1', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--gradient_accumulation_steps', '1', '--evaluation_strategy', 'no', '--save_strategy', 'steps', '--save_steps', '50000', '--save_total_limit', '1', '--learning_rate', '2e-4', '--weight_decay', '0.', '--warmup_ratio', '0.03', '--lr_scheduler_type', 'cosine', '--logging_steps', '1', '--tf32', 'True', '--model_max_length', '2048', '--gradient_checkpointing', 'True', '--dataloader_num_workers', '4', '--lazy_preprocess', 'True', '--report_to', 'wandb'] exits with return code = 1






(base) [jjls2000@login1 [dmog] Dissertation]$ cat llava-med-test-87583.err
Traceback (most recent call last):
  File "/users/jjls2000/sharedscratch/Dissertation/llava/train/train_mem.py", line 1, in <module>
    from llava.train.train import train
  File "/mnt/scratch/users/jjls2000/Dissertation/llava/__init__.py", line 1, in <module>
    from .model import LlavaLlamaForCausalLM
  File "/mnt/scratch/users/jjls2000/Dissertation/llava/model/__init__.py", line 2, in <module>
    from .language_model.llava_llama import LlavaLlamaForCausalLM, LlavaConfig
  File "/mnt/scratch/users/jjls2000/Dissertation/llava/model/language_model/llava_llama.py", line 21, in <module>
    from transformers import AutoConfig, AutoModelForCausalLM, \
  File "/users/jjls2000/.local/lib/python3.10/site-packages/transformers/__init__.py", line 26, in <module>
    from . import dependency_versions_check
  File "/users/jjls2000/.local/lib/python3.10/site-packages/transformers/dependency_versions_check.py", line 16, in <module>
    from .utils.versions import require_version, require_version_core
  File "/users/jjls2000/.local/lib/python3.10/site-packages/transformers/utils/__init__.py", line 30, in <module>
    from .generic import (
  File "/users/jjls2000/.local/lib/python3.10/site-packages/transformers/utils/generic.py", line 29, in <module>
    from .import_utils import is_flax_available, is_tf_available, is_torch_available, is_torch_fx_proxy
  File "/users/jjls2000/.local/lib/python3.10/site-packages/transformers/utils/import_utils.py", line 34, in <module>
    from . import logging
  File "/users/jjls2000/.local/lib/python3.10/site-packages/transformers/utils/logging.py", line 35, in <module>
    import huggingface_hub.utils as hf_hub_utils
  File "/users/jjls2000/.local/lib/python3.10/site-packages/huggingface_hub/utils/__init__.py", line 19, in <module>
    from huggingface_hub.errors import (
  File "/users/jjls2000/.local/lib/python3.10/site-packages/huggingface_hub/errors.py", line 3, in <module>
    from requests import HTTPError
  File "/users/jjls2000/.conda/envs/llava_med/lib/python3.10/site-packages/requests/__init__.py", line 48, in <module>
    from charset_normalizer import __version__ as charset_normalizer_version
  File "/users/jjls2000/.conda/envs/llava_med/lib/python3.10/site-packages/charset_normalizer/__init__.py", line 23, in <module>
    from charset_normalizer.api import from_fp, from_path, from_bytes, normalize
  File "/users/jjls2000/.conda/envs/llava_med/lib/python3.10/site-packages/charset_normalizer/api.py", line 10, in <module>
    from charset_normalizer.md import mess_ratio
AttributeError: partially initialized module 'charset_normalizer' has no attribute 'md__mypyc' (most likely due to a circular import)

(base) [jjls2000@login1 [dmog] Dissertation]$ cat llava-med-test-87583.out
[2024-07-14 16:24:29,725] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-07-14 16:24:30,527] [WARNING] [runner.py:196:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
Detected CUDA_VISIBLE_DEVICES=0: setting --include=localhost:0
[2024-07-14 16:24:32,958] [INFO] [runner.py:555:main] cmd = /users/jjls2000/.conda/envs/llava_med/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMF19 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None /users/jjls2000/sharedscratch/Dissertation/llava/train/train_mem.py --lora_enable True --lora_r 128 --lora_alpha 256 --mm_projector_lr 2e-5 --deepspeed /users/jjls2000/sharedscratch/Dissertation/scripts/zero3.json --model_name_or_path /users/jjls2000/sharedscratch/Dissertation/checkpoints/llava-v1.5-7b --version llava_v1.5 --data_path /users/jjls2000/sharedscratch/Dissertation/Slake1.0/augmented/BBF_train.json --image_folder /users/jjls2000/sharedscratch/Dissertation/data/imgs-1 --vision_tower openai/clip-vit-large-patch14-336 --pretrain_mm_mlp_adapter /users/jjls2000/sharedscratch/Dissertation/checkpoints/llava-v1.5-7b/mm_projector_extracted/mm_projector/data.pkl --mm_projector_type mlp2x_gelu --mm_vision_select_layer -2 --mm_use_im_start_end False --mm_use_im_patch_token False --image_aspect_ratio pad --group_by_modality_length True --bf16 True --output_dir /users/jjls2000/sharedscratch/Dissertation/results/20240709_214950 --num_train_epochs 1 --per_device_train_batch_size 16 --per_device_eval_batch_size 4 --gradient_accumulation_steps 1 --evaluation_strategy no --save_strategy steps --save_steps 50000 --save_total_limit 1 --learning_rate 2e-4 --weight_decay 0. --warmup_ratio 0.03 --lr_scheduler_type cosine --logging_steps 1 --tf32 True --model_max_length 2048 --gradient_checkpointing True --dataloader_num_workers 4 --lazy_preprocess True --report_to wandb
[2024-07-14 16:24:34,195] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-07-14 16:24:34,460] [INFO] [launch.py:145:main] WORLD INFO DICT: {'localhost': [0]}
[2024-07-14 16:24:34,461] [INFO] [launch.py:151:main] nnodes=1, num_local_procs=1, node_rank=0
[2024-07-14 16:24:34,461] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})
[2024-07-14 16:24:34,461] [INFO] [launch.py:163:main] dist_world_size=1
[2024-07-14 16:24:34,461] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0
[2024-07-14 16:24:36,463] [INFO] [launch.py:315:sigkill_handler] Killing subprocess 2962627
[2024-07-14 16:24:36,463] [ERROR] [launch.py:321:sigkill_handler] ['/users/jjls2000/.conda/envs/llava_med/bin/python', '-u', '/users/jjls2000/sharedscratch/Dissertation/llava/train/train_mem.py', '--local_rank=0', '--lora_enable', 'True', '--lora_r', '128', '--lora_alpha', '256', '--mm_projector_lr', '2e-5', '--deepspeed', '/users/jjls2000/sharedscratch/Dissertation/scripts/zero3.json', '--model_name_or_path', '/users/jjls2000/sharedscratch/Dissertation/checkpoints/llava-v1.5-7b', '--version', 'llava_v1.5', '--data_path', '/users/jjls2000/sharedscratch/Dissertation/Slake1.0/augmented/BBF_train.json', '--image_folder', '/users/jjls2000/sharedscratch/Dissertation/data/imgs-1', '--vision_tower', 'openai/clip-vit-large-patch14-336', '--pretrain_mm_mlp_adapter', '/users/jjls2000/sharedscratch/Dissertation/checkpoints/llava-v1.5-7b/mm_projector_extracted/mm_projector/data.pkl', '--mm_projector_type', 'mlp2x_gelu', '--mm_vision_select_layer', '-2', '--mm_use_im_start_end', 'False', '--mm_use_im_patch_token', 'False', '--image_aspect_ratio', 'pad', '--group_by_modality_length', 'True', '--bf16', 'True', '--output_dir', '/users/jjls2000/sharedscratch/Dissertation/results/20240709_214950', '--num_train_epochs', '1', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--gradient_accumulation_steps', '1', '--evaluation_strategy', 'no', '--save_strategy', 'steps', '--save_steps', '50000', '--save_total_limit', '1', '--learning_rate', '2e-4', '--weight_decay', '0.', '--warmup_ratio', '0.03', '--lr_scheduler_type', 'cosine', '--logging_steps', '1', '--tf32', 'True', '--model_max_length', '2048', '--gradient_checkpointing', 'True', '--dataloader_num_workers', '4', '--lazy_preprocess', 'True', '--report_to', 'wandb'] exits with return code = 1







(base) [jjls2000@login1 [dmog] Dissertation]$ cat llava-med-test-87726.err
Traceback (most recent call last):
  File "/users/jjls2000/.local/bin/deepspeed", line 3, in <module>
    from deepspeed.launcher.runner import main
  File "/users/jjls2000/.local/lib/python3.10/site-packages/deepspeed/__init__.py", line 16, in <module>
    from . import module_inject
  File "/users/jjls2000/.local/lib/python3.10/site-packages/deepspeed/module_inject/__init__.py", line 6, in <module>
    from .replace_module import replace_transformer_layer, revert_transformer_layer, ReplaceWithTensorSlicing, GroupQuantizer, generic_injection
  File "/users/jjls2000/.local/lib/python3.10/site-packages/deepspeed/module_inject/replace_module.py", line 792, in <module>
    from ..pipe import PipelineModule
  File "/users/jjls2000/.local/lib/python3.10/site-packages/deepspeed/pipe/__init__.py", line 6, in <module>
    from ..runtime.pipe import PipelineModule, LayerSpec, TiedLayerSpec
  File "/users/jjls2000/.local/lib/python3.10/site-packages/deepspeed/runtime/pipe/__init__.py", line 6, in <module>
    from .module import PipelineModule, LayerSpec, TiedLayerSpec
  File "/users/jjls2000/.local/lib/python3.10/site-packages/deepspeed/runtime/pipe/module.py", line 19, in <module>
    from ..activation_checkpointing import checkpointing
  File "/users/jjls2000/.local/lib/python3.10/site-packages/deepspeed/runtime/activation_checkpointing/checkpointing.py", line 25, in <module>
    from deepspeed.runtime.config import DeepSpeedConfig
  File "/users/jjls2000/.local/lib/python3.10/site-packages/deepspeed/runtime/config.py", line 24, in <module>
    from .config_utils import (
  File "/users/jjls2000/.local/lib/python3.10/site-packages/deepspeed/runtime/config_utils.py", line 12, in <module>
    from pydantic import BaseModel
ModuleNotFoundError: No module named 'pydantic'

(base) [jjls2000@login1 [dmog] Dissertation]$ cat llava-med-test-87726.out
[2024-07-15 14:40:50,637] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
(base) [jjls2000@login1 [dmog] Dissertation]$ 
