{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'img_id': 1, 'img_name': 'xmlab1/source.jpg', 'question': 'What modality is used to take this image?', 'answer': 'MRI', 'q_lang': 'en', 'location': 'Abdomen', 'modality': 'MRI', 'answer_type': 'OPEN', 'base_type': 'vqa', 'content_type': 'Modality', 'triple': ['vhead', '_', '_'], 'qid': 0}, {'img_id': 1, 'img_name': 'xmlab1/source.jpg', 'question': 'Which part of the body does this image belong to?', 'answer': 'Abdomen', 'q_lang': 'en', 'location': 'Abdomen', 'modality': 'MRI', 'answer_type': 'OPEN', 'base_type': 'vqa', 'content_type': 'Position', 'triple': ['vhead', '_', '_'], 'qid': 1}, {'img_id': 1, 'img_name': 'xmlab1/source.jpg', 'question': 'What is the mr weighting in this image?', 'answer': 'T2', 'q_lang': 'en', 'location': 'Abdomen', 'modality': 'MRI', 'answer_type': 'OPEN', 'base_type': 'vqa', 'content_type': 'Modality', 'triple': ['vhead', '_', '_'], 'qid': 2}]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Path to the original train.json file\n",
    "train_json_path = '/Users/jeffreysherer/Desktop/Dissertation/Slake1.0/train.json'\n",
    "\n",
    "# Load the train.json file\n",
    "with open(train_json_path, 'r') as file:\n",
    "    train_data = json.load(file)\n",
    "\n",
    "# Display the first few entries to verify the content\n",
    "print(train_data[:3])  # Adjust the number of entries to display based on your need\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Liver': [54.0, 106.0, 30.0, 31.0]}]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def load_detection_json(img_folder):\n",
    "    # Path to the folder containing detection.json\n",
    "    detection_json_path = os.path.join('/Users/jeffreysherer/Dissertation/data/imgs-1', img_folder, 'detection.json')\n",
    "    \n",
    "    # Load the detection.json file\n",
    "    if os.path.exists(detection_json_path):\n",
    "        with open(detection_json_path, 'r') as file:\n",
    "            detection_data = json.load(file)\n",
    "        return detection_data\n",
    "    else:\n",
    "        return None  # Return None if file does not exist\n",
    "\n",
    "# Test the function with an example folder\n",
    "example_folder = 'xmlab1'\n",
    "example_detection = load_detection_json(example_folder)\n",
    "print(example_detection)  # Display the content of the detection.json for verification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'img_id': 1, 'img_name': 'xmlab1/source.jpg', 'question': 'What modality is used to take this image?', 'answer': 'MRI', 'q_lang': 'en', 'location': 'Abdomen', 'modality': 'MRI', 'answer_type': 'OPEN', 'base_type': 'vqa', 'content_type': 'Modality', 'triple': ['vhead', '_', '_'], 'qid': 0, 'detection': [{'Liver': [54.0, 106.0, 30.0, 31.0]}]}, {'img_id': 1, 'img_name': 'xmlab1/source.jpg', 'question': 'Which part of the body does this image belong to?', 'answer': 'Abdomen', 'q_lang': 'en', 'location': 'Abdomen', 'modality': 'MRI', 'answer_type': 'OPEN', 'base_type': 'vqa', 'content_type': 'Position', 'triple': ['vhead', '_', '_'], 'qid': 1, 'detection': [{'Liver': [54.0, 106.0, 30.0, 31.0]}]}, {'img_id': 1, 'img_name': 'xmlab1/source.jpg', 'question': 'What is the mr weighting in this image?', 'answer': 'T2', 'q_lang': 'en', 'location': 'Abdomen', 'modality': 'MRI', 'answer_type': 'OPEN', 'base_type': 'vqa', 'content_type': 'Modality', 'triple': ['vhead', '_', '_'], 'qid': 2, 'detection': [{'Liver': [54.0, 106.0, 30.0, 31.0]}]}]\n"
     ]
    }
   ],
   "source": [
    "# Function to add detection data to train_data entries\n",
    "def integrate_detection_data(train_data):\n",
    "    for item in train_data:\n",
    "        # Extract the folder name from img_name\n",
    "        folder_name = item['img_name'].split('/')[0]\n",
    "        \n",
    "        # Load detection data for the corresponding folder\n",
    "        detection_data = load_detection_json(folder_name)\n",
    "        \n",
    "        # If detection data exists, add it to the train data item\n",
    "        if detection_data:\n",
    "            item['detection'] = detection_data\n",
    "    \n",
    "    return train_data\n",
    "\n",
    "# Update train_data with detection information\n",
    "updated_train_data = integrate_detection_data(train_data)\n",
    "\n",
    "# Print a few updated entries to verify that detection data has been added correctly\n",
    "print(updated_train_data[:3])  # Adjust the number of entries to display based on your need\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated train.json has been saved to /Users/jeffreysherer/Desktop/Dissertation/Slake1.0/augmented/updated_train.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import uuid  # To generate unique IDs\n",
    "\n",
    "# Base path where the original train.json is located\n",
    "base_path = '/Users/jeffreysherer/Desktop/Dissertation/Slake1.0'\n",
    "\n",
    "# Directory containing the image folders with detection.json files\n",
    "image_directory = '/Users/jeffreysherer/Dissertation/data/imgs-1'\n",
    "\n",
    "# Path to the original train.json file\n",
    "train_json_path = os.path.join(base_path, 'train.json')\n",
    "\n",
    "# Load the train.json file\n",
    "with open(train_json_path, 'r') as file:\n",
    "    train_data = json.load(file)\n",
    "\n",
    "# Function to update the data with bounding box coordinates\n",
    "def update_data_with_bounding_boxes(data):\n",
    "    for entry in data:\n",
    "        img_folder = os.path.dirname(entry['img_name'])\n",
    "        detection_json_path = os.path.join(image_directory, img_folder, 'detection.json')\n",
    "\n",
    "        if os.path.exists(detection_json_path):\n",
    "            with open(detection_json_path, 'r') as file:\n",
    "                detection_data = json.load(file)\n",
    "            entry['detection'] = detection_data\n",
    "\n",
    "    return data\n",
    "\n",
    "# Update the train data with bounding box coordinates\n",
    "updated_train_data = update_data_with_bounding_boxes(train_data)\n",
    "\n",
    "# Function to transform the data to the required format\n",
    "def transform_data(data):\n",
    "    transformed_data = []\n",
    "    for entry in data:\n",
    "        unique_id = str(uuid.uuid4())  # Generate a unique ID for each entry\n",
    "        img_path = entry['img_name']  # Use the img_name as the image path\n",
    "        question = entry['question']\n",
    "        answer = entry['answer']\n",
    "        \n",
    "        transformed_entry = {\n",
    "            \"id\": unique_id,\n",
    "            \"image\": img_path,\n",
    "            \"conversations\": [\n",
    "                {\n",
    "                    \"from\": \"human\",\n",
    "                    \"value\": f\"<image>\\n{question}\"\n",
    "                },\n",
    "                {\n",
    "                    \"from\": \"gpt\",\n",
    "                    \"value\": answer\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "        if 'detection' in entry:\n",
    "            transformed_entry['detection'] = entry['detection']\n",
    "        transformed_data.append(transformed_entry)\n",
    "    return transformed_data\n",
    "\n",
    "# Transform the train data\n",
    "transformed_train_data = transform_data(updated_train_data)\n",
    "\n",
    "# Path to save the final train.json file\n",
    "final_train_json_path = os.path.join(augmented_dir, 'final_train.json')\n",
    "\n",
    "# Write the transformed train data to a new JSON file\n",
    "with open(final_train_json_path, 'w') as file:\n",
    "    json.dump(transformed_train_data, file, indent=4)\n",
    "\n",
    "print(\"Final train.json has been saved to\", final_train_json_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed train.json has been saved to /Users/jeffreysherer/Desktop/Dissertation/Slake1.0/augmented/transformed_train.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import uuid  # To generate unique IDs\n",
    "\n",
    "# Assuming 'updated_train_data' is already defined from the previous cell\n",
    "\n",
    "# Transform the data to the required format\n",
    "transformed_data = []\n",
    "for entry in updated_train_data:\n",
    "    unique_id = str(uuid.uuid4())  # Generate a unique ID for each entry\n",
    "    img_path = entry['img_name']  # Use the img_name as the image path\n",
    "    question = entry['question']\n",
    "    answer = entry['answer']\n",
    "    \n",
    "    transformed_entry = {\n",
    "        \"id\": unique_id,\n",
    "        \"image\": img_path,\n",
    "        \"conversations\": [\n",
    "            {\n",
    "                \"from\": \"human\",\n",
    "                \"value\": f\"<image>\\n{question}\"\n",
    "            },\n",
    "            {\n",
    "                \"from\": \"gpt\",\n",
    "                \"value\": answer\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    if 'detection' in entry:\n",
    "        transformed_entry['detection'] = entry['detection']\n",
    "    transformed_data.append(transformed_entry)\n",
    "\n",
    "# Path to save the final transformed JSON file\n",
    "final_train_json_path = '/Users/jeffreysherer/Desktop/Dissertation/Slake1.0/augmented/final_train.json'\n",
    "\n",
    "# Write the transformed data to a new JSON file\n",
    "with open(final_train_json_path, 'w') as file:\n",
    "    json.dump(transformed_data, file, indent=4)\n",
    "\n",
    "print(\"Final train.json has been saved to\", final_train_json_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"id\": \"a6ff7415-de7f-4270-af38-d750f726e01c\",\n",
      "    \"image\": \"xmlab423/source.jpg\",\n",
      "    \"conversations\": [\n",
      "        {\n",
      "            \"from\": \"human\",\n",
      "            \"value\": \"<image>\\n\\u989e\\u53f6\\u51fa\\u73b0\\u5728\\u8fd9\\u5f20\\u56fe\\u4e0a\\u4e86\\u5417?\"\n",
      "        },\n",
      "        {\n",
      "            \"from\": \"gpt\",\n",
      "            \"value\": \"\\u6ca1\\u6709\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"id\": \"533450c3-7d36-4dfc-a833-4c181d09e39b\",\n",
      "    \"image\": \"xmlab275/source.jpg\",\n",
      "    \"conversations\": [\n",
      "        {\n",
      "            \"from\": \"human\",\n",
      "            \"value\": \"<image>\\nWhere is the liver?\"\n",
      "        },\n",
      "        {\n",
      "            \"from\": \"gpt\",\n",
      "            \"value\": \"Left\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"id\": \"0dd1fc6e-d2f9-4516-8d18-7f2b9776cbd3\",\n",
      "    \"image\": \"xmlab190/source.jpg\",\n",
      "    \"conversations\": [\n",
      "        {\n",
      "            \"from\": \"human\",\n",
      "            \"value\": \"<image>\\nDoes this image look abnormal?\"\n",
      "        },\n",
      "        {\n",
      "            \"from\": \"gpt\",\n",
      "            \"value\": \"Yes\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"id\": \"099138e8-ded5-4cac-9854-e98750e34aa0\",\n",
      "    \"image\": \"xmlab279/source.jpg\",\n",
      "    \"conversations\": [\n",
      "        {\n",
      "            \"from\": \"human\",\n",
      "            \"value\": \"<image>\\n\\u56fe\\u7247\\u4e2d\\u5305\\u542b\\u813e\\u810f\\u5417?\"\n",
      "        },\n",
      "        {\n",
      "            \"from\": \"gpt\",\n",
      "            \"value\": \"\\u4e0d\\u5305\\u542b\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"id\": \"781b0632-7f79-4edc-8bfe-df017bda8912\",\n",
      "    \"image\": \"xmlab370/source.jpg\",\n",
      "    \"conversations\": [\n",
      "        {\n",
      "            \"from\": \"human\",\n",
      "            \"value\": \"<image>\\nWhich type of modality is shown about this image, MRI, CT or X-Ray?\"\n",
      "        },\n",
      "        {\n",
      "            \"from\": \"gpt\",\n",
      "            \"value\": \"X-Ray\"\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "# Path to the transformed train.json file\n",
    "transformed_train_json_path = '/Users/jeffreysherer/Desktop/Dissertation/Slake1.0/augmented/transformed_train.json'\n",
    "\n",
    "# Load the transformed train.json file\n",
    "with open(transformed_train_json_path, 'r') as file:\n",
    "    transformed_data = json.load(file)\n",
    "\n",
    "# Randomly sample 5 entries from the dataset to inspect\n",
    "sampled_entries = random.sample(transformed_data, 5)\n",
    "\n",
    "# Print the sampled entries\n",
    "for entry in sampled_entries:\n",
    "    print(json.dumps(entry, indent=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now doing the trst adn validate json files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"id\": \"4c769b41-5e40-4b8c-b8ab-faed96555178\",\n",
      "        \"image\": \"xmlab0/source.jpg\",\n",
      "        \"conversations\": [\n",
      "            {\n",
      "                \"from\": \"human\",\n",
      "                \"value\": \"<image>\\nWhat modality is used to take this image?\"\n",
      "            },\n",
      "            {\n",
      "                \"from\": \"gpt\",\n",
      "                \"value\": \"MRI\"\n",
      "            }\n",
      "        ]\n",
      "    },\n",
      "    {\n",
      "        \"id\": \"cdd7f275-d48f-459a-b27c-654dbcaa6dac\",\n",
      "        \"image\": \"xmlab0/source.jpg\",\n",
      "        \"conversations\": [\n",
      "            {\n",
      "                \"from\": \"human\",\n",
      "                \"value\": \"<image>\\nWhich part of the body does this image belong to?\"\n",
      "            },\n",
      "            {\n",
      "                \"from\": \"gpt\",\n",
      "                \"value\": \"Abdomen\"\n",
      "            }\n",
      "        ]\n",
      "    },\n",
      "    {\n",
      "        \"id\": \"206f195c-88cf-41d7-a967-110232eeee17\",\n",
      "        \"image\": \"xmlab0/source.jpg\",\n",
      "        \"conversations\": [\n",
      "            {\n",
      "                \"from\": \"human\",\n",
      "                \"value\": \"<image>\\nWhat is the mr weighting in this image?\"\n",
      "            },\n",
      "            {\n",
      "                \"from\": \"gpt\",\n",
      "                \"value\": \"T2\"\n",
      "            }\n",
      "        ]\n",
      "    }\n",
      "]\n",
      "[\n",
      "    {\n",
      "        \"id\": \"3aac250e-5f79-4baf-b2ba-da55e81dce9f\",\n",
      "        \"image\": \"xmlab102/source.jpg\",\n",
      "        \"conversations\": [\n",
      "            {\n",
      "                \"from\": \"human\",\n",
      "                \"value\": \"<image>\\nWhat modality is used to take this image?\"\n",
      "            },\n",
      "            {\n",
      "                \"from\": \"gpt\",\n",
      "                \"value\": \"CT\"\n",
      "            }\n",
      "        ]\n",
      "    },\n",
      "    {\n",
      "        \"id\": \"a4b2359a-e83c-4026-b25a-94c39948f999\",\n",
      "        \"image\": \"xmlab102/source.jpg\",\n",
      "        \"conversations\": [\n",
      "            {\n",
      "                \"from\": \"human\",\n",
      "                \"value\": \"<image>\\nWhich part of the body does this image belong to?\"\n",
      "            },\n",
      "            {\n",
      "                \"from\": \"gpt\",\n",
      "                \"value\": \"Chest\"\n",
      "            }\n",
      "        ]\n",
      "    },\n",
      "    {\n",
      "        \"id\": \"f9894e48-262e-4797-83d2-6c474ad822c1\",\n",
      "        \"image\": \"xmlab102/source.jpg\",\n",
      "        \"conversations\": [\n",
      "            {\n",
      "                \"from\": \"human\",\n",
      "                \"value\": \"<image>\\nWhat is the main organ in the image?\"\n",
      "            },\n",
      "            {\n",
      "                \"from\": \"gpt\",\n",
      "                \"value\": \"Lung, Spinal Cord\"\n",
      "            }\n",
      "        ]\n",
      "    }\n",
      "]\n",
      "Transformed validate.json has been saved to /Users/jeffreysherer/Desktop/Dissertation/Slake1.0/augmented/transformed_validate.json\n",
      "Transformed test.json has been saved to /Users/jeffreysherer/Desktop/Dissertation/Slake1.0/augmented/transformed_test.json\n",
      "Updated transformed validate.json with bounding boxes has been saved to /Users/jeffreysherer/Desktop/Dissertation/Slake1.0/augmented/updated_transformed_validate.json\n",
      "Updated transformed test.json with bounding boxes has been saved to /Users/jeffreysherer/Desktop/Dissertation/Slake1.0/augmented/updated_transformed_test.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import uuid  # To generate unique IDs\n",
    "import os\n",
    "\n",
    "# Paths to the original validate.json and test.json files\n",
    "validate_json_path = '/Users/jeffreysherer/Desktop/Dissertation/Slake1.0/validate.json'\n",
    "test_json_path = '/Users/jeffreysherer/Desktop/Dissertation/Slake1.0/test.json'\n",
    "\n",
    "# Load the validate.json file\n",
    "with open(validate_json_path, 'r') as file:\n",
    "    validate_data = json.load(file)\n",
    "\n",
    "# Load the test.json file\n",
    "with open(test_json_path, 'r') as file:\n",
    "    test_data = json.load(file)\n",
    "\n",
    "# Function to transform the data\n",
    "def transform_data(data):\n",
    "    transformed_data = []\n",
    "    for entry in data:\n",
    "        unique_id = str(uuid.uuid4())  # Generate a unique ID for each entry\n",
    "        img_path = entry['img_name']  # Use the img_name as the image path\n",
    "        question = entry['question']\n",
    "        answer = entry['answer']\n",
    "        \n",
    "        transformed_entry = {\n",
    "            \"id\": unique_id,\n",
    "            \"image\": img_path,\n",
    "            \"conversations\": [\n",
    "                {\n",
    "                    \"from\": \"human\",\n",
    "                    \"value\": f\"<image>\\n{question}\"\n",
    "                },\n",
    "                {\n",
    "                    \"from\": \"gpt\",\n",
    "                    \"value\": answer\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "        transformed_data.append(transformed_entry)\n",
    "    return transformed_data\n",
    "\n",
    "# Transform validate and test data\n",
    "transformed_validate_data = transform_data(validate_data)\n",
    "transformed_test_data = transform_data(test_data)\n",
    "\n",
    "# Display the first few entries to verify the content\n",
    "print(json.dumps(transformed_validate_data[:3], indent=4))  # Adjust the number of entries to display based on your need\n",
    "print(json.dumps(transformed_test_data[:3], indent=4))  # Adjust the number of entries to display based on your need\n",
    "\n",
    "# Paths to save the transformed JSON files\n",
    "transformed_validate_json_path = '/Users/jeffreysherer/Desktop/Dissertation/Slake1.0/augmented/transformed_validate.json'\n",
    "transformed_test_json_path = '/Users/jeffreysherer/Desktop/Dissertation/Slake1.0/augmented/transformed_test.json'\n",
    "\n",
    "# Write the transformed validate data to a new JSON file\n",
    "with open(transformed_validate_json_path, 'w') as file:\n",
    "    json.dump(transformed_validate_data, file, indent=4)\n",
    "\n",
    "# Write the transformed test data to a new JSON file\n",
    "with open(transformed_test_json_path, 'w') as file:\n",
    "    json.dump(transformed_test_data, file, indent=4)\n",
    "\n",
    "print(\"Transformed validate.json has been saved to\", transformed_validate_json_path)\n",
    "print(\"Transformed test.json has been saved to\", transformed_test_json_path)\n",
    "\n",
    "# Directory containing the image folders with detection.json files\n",
    "image_directory = '/Users/jeffreysherer/Dissertation/data/imgs-1'\n",
    "\n",
    "# Function to update the data with bounding box coordinates\n",
    "def update_data_with_bounding_boxes(transformed_data):\n",
    "    for entry in transformed_data:\n",
    "        # Extract the original image path\n",
    "        img_path = entry['image']\n",
    "        img_folder = os.path.dirname(img_path)\n",
    "        detection_json_path = os.path.join(image_directory, img_folder, 'detection.json')\n",
    "        \n",
    "        if os.path.exists(detection_json_path):\n",
    "            with open(detection_json_path, 'r') as file:\n",
    "                detection_data = json.load(file)\n",
    "            entry['detection'] = detection_data\n",
    "\n",
    "    return transformed_data\n",
    "\n",
    "# Update the transformed validate and test data with bounding box coordinates\n",
    "updated_validate_data = update_data_with_bounding_boxes(transformed_validate_data)\n",
    "updated_test_data = update_data_with_bounding_boxes(transformed_test_data)\n",
    "\n",
    "# Paths to save the updated JSON files with bounding boxes\n",
    "updated_validate_json_path = '/Users/jeffreysherer/Desktop/Dissertation/Slake1.0/augmented/updated_transformed_validate.json'\n",
    "updated_test_json_path = '/Users/jeffreysherer/Desktop/Dissertation/Slake1.0/augmented/updated_transformed_test.json'\n",
    "\n",
    "# Write the updated validate data to a new JSON file\n",
    "with open(updated_validate_json_path, 'w') as file:\n",
    "    json.dump(updated_validate_data, file, indent=4)\n",
    "\n",
    "# Write the updated test data to a new JSON file\n",
    "with open(updated_test_json_path, 'w') as file:\n",
    "    json.dump(updated_test_data, file, indent=4)\n",
    "\n",
    "print(\"Updated transformed validate.json with bounding boxes has been saved to\", updated_validate_json_path)\n",
    "print(\"Updated transformed test.json with bounding boxes has been saved to\", updated_test_json_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated transformed validate.json with bounding boxes has been saved to /Users/jeffreysherer/Desktop/Dissertation/Slake1.0/augmented/updated_transformed_validate.json\n",
      "Updated transformed test.json with bounding boxes has been saved to /Users/jeffreysherer/Desktop/Dissertation/Slake1.0/augmented/updated_transformed_test.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# Directory containing the image folders with detection.json files\n",
    "image_directory = '/Users/jeffreysherer/Dissertation/data/imgs-1'\n",
    "\n",
    "# Function to update the data with bounding box coordinates\n",
    "def update_data_with_bounding_boxes(transformed_data):\n",
    "    for entry in transformed_data:\n",
    "        # Extract the original image path\n",
    "        img_path = entry['image']\n",
    "        img_folder = os.path.dirname(img_path)\n",
    "        detection_json_path = os.path.join(image_directory, img_folder, 'detection.json')\n",
    "        \n",
    "        if os.path.exists(detection_json_path):\n",
    "            with open(detection_json_path, 'r') as file:\n",
    "                detection_data = json.load(file)\n",
    "            entry['detection'] = detection_data\n",
    "\n",
    "    return transformed_data\n",
    "\n",
    "# Load transformed validate and test data\n",
    "transformed_validate_json_path = '/Users/jeffreysherer/Desktop/Dissertation/Slake1.0/augmented/transformed_validate.json'\n",
    "transformed_test_json_path = '/Users/jeffreysherer/Desktop/Dissertation/Slake1.0/augmented/transformed_test.json'\n",
    "\n",
    "with open(transformed_validate_json_path, 'r') as file:\n",
    "    transformed_validate_data = json.load(file)\n",
    "\n",
    "with open(transformed_test_json_path, 'r') as file:\n",
    "    transformed_test_data = json.load(file)\n",
    "\n",
    "# Update the transformed validate and test data with bounding box coordinates\n",
    "updated_validate_data = update_data_with_bounding_boxes(transformed_validate_data)\n",
    "updated_test_data = update_data_with_bounding_boxes(transformed_test_data)\n",
    "\n",
    "# Paths to save the updated JSON files with bounding boxes\n",
    "updated_validate_json_path = '/Users/jeffreysherer/Desktop/Dissertation/Slake1.0/augmented/updated_transformed_validate.json'\n",
    "updated_test_json_path = '/Users/jeffreysherer/Desktop/Dissertation/Slake1.0/augmented/updated_transformed_test.json'\n",
    "\n",
    "# Write the updated validate data to a new JSON file\n",
    "with open(updated_validate_json_path, 'w') as file:\n",
    "    json.dump(updated_validate_data, file, indent=4)\n",
    "\n",
    "# Write the updated test data to a new JSON file\n",
    "with open(updated_test_json_path, 'w') as file:\n",
    "    json.dump(updated_test_data, file, indent=4)\n",
    "\n",
    "print(\"Updated transformed validate.json with bounding boxes has been saved to\", updated_validate_json_path)\n",
    "print(\"Updated transformed test.json with bounding boxes has been saved to\", updated_test_json_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated validate.json has been saved to /Users/jeffreysherer/Desktop/Dissertation/Slake1.0/augmented/BBF_validate.json\n",
      "Updated test.json has been saved to /Users/jeffreysherer/Desktop/Dissertation/Slake1.0/augmented/BBF_test.json\n"
     ]
    }
   ],
   "source": [
    "# Paths to save the updated validate and test JSON files\n",
    "augmented_folder = '/Users/jeffreysherer/Desktop/Dissertation/Slake1.0/augmented'\n",
    "updated_validate_json_path = os.path.join(augmented_folder, 'BBF_validate.json')\n",
    "updated_test_json_path = os.path.join(augmented_folder, 'BBF_test.json')\n",
    "\n",
    "# Ensure the augmented folder exists\n",
    "os.makedirs(augmented_folder, exist_ok=True)\n",
    "\n",
    "# Write the updated validate data to a new JSON file\n",
    "with open(updated_validate_json_path, 'w') as file:\n",
    "    json.dump(updated_validate_data, file, indent=4)\n",
    "\n",
    "# Write the updated test data to a new JSON file\n",
    "with open(updated_test_json_path, 'w') as file:\n",
    "    json.dump(updated_test_data, file, indent=4)\n",
    "\n",
    "print(\"Updated validate.json has been saved to\", updated_validate_json_path)\n",
    "print(\"Updated test.json has been saved to\", updated_test_json_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
