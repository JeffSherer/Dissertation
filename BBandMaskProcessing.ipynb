{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data downloaded and saved successfully to train.json!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# URL pointing directly to the raw JSON data\n",
    "url = 'https://huggingface.co/datasets/BoKelvin/SLAKE/raw/main/train.json'\n",
    "\n",
    "# Sending a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    try:\n",
    "        # Load the JSON data\n",
    "        data = response.json()\n",
    "        \n",
    "        # Specify the filename\n",
    "        filename = 'train.json'\n",
    "        \n",
    "        # Write JSON data to a file\n",
    "        with open(filename, 'w') as file:\n",
    "            json.dump(data, file, indent=4)\n",
    "        \n",
    "        print(f\"Data downloaded and saved successfully to {filename}!\")\n",
    "        \n",
    "    except ValueError as e:\n",
    "        print(\"Failed to decode JSON: \", e)\n",
    "else:\n",
    "    print(\"Failed to download data. Status code:\", response.status_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique keys in the JSON file:\n",
      "content_type\n",
      "modality\n",
      "question\n",
      "base_type\n",
      "triple\n",
      "q_lang\n",
      "answer\n",
      "location\n",
      "qid\n",
      "answer_type\n",
      "img_id\n",
      "img_name\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def find_keys(obj, keys_set):\n",
    "    \"\"\" Recursively find all keys in a JSON object and add them to a set. \"\"\"\n",
    "    if isinstance(obj, dict):\n",
    "        for key, value in obj.items():\n",
    "            keys_set.add(key)\n",
    "            find_keys(value, keys_set)\n",
    "    elif isinstance(obj, list):\n",
    "        for item in obj:\n",
    "            find_keys(item, keys_set)\n",
    "\n",
    "def main():\n",
    "    filename = 'train.json'  # Path to your JSON file\n",
    "\n",
    "    # Load the JSON data from the file\n",
    "    try:\n",
    "        with open(filename, 'r') as file:\n",
    "            data = json.load(file)\n",
    "        \n",
    "        # Set to store unique keys\n",
    "        unique_keys = set()\n",
    "        \n",
    "        # Find all unique keys in the JSON data\n",
    "        find_keys(data, unique_keys)\n",
    "        \n",
    "        # Print all unique keys\n",
    "        print(\"Unique keys in the JSON file:\")\n",
    "        for key in unique_keys:\n",
    "            print(key)\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file {filename} does not exist.\")\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"Error: Failed to decode JSON from the file.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded successfully: /Users/jeffreysherer/Downloads/BBandMaskProcessing/imgs.zip\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "# Define the URL and the download path\n",
    "url = 'https://huggingface.co/datasets/BoKelvin/SLAKE/raw/main/imgs.zip'\n",
    "download_path = '/Users/jeffreysherer/Downloads/BBandMaskProcessing/imgs.zip'\n",
    "\n",
    "# Create directory if it does not exist\n",
    "os.makedirs(os.path.dirname(download_path), exist_ok=True)\n",
    "\n",
    "try:\n",
    "    # Download the file\n",
    "    response = requests.get(url, stream=True, timeout=10)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    # Write to file\n",
    "    with open(download_path, 'wb') as file:\n",
    "        for chunk in response.iter_content(chunk_size=8192):\n",
    "            file.write(chunk)\n",
    "\n",
    "    print(f\"File downloaded successfully: {download_path}\")\n",
    "\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"Download failed: {e}\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"File not found error: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/teamspace/studios/this_studio/imgs.zip is not a valid zip file or is corrupted.\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "\n",
    "zip_path = '/teamspace/studios/this_studio/imgs.zip'\n",
    "\n",
    "# Check if the file is a valid zip file\n",
    "is_zip = zipfile.is_zipfile(zip_path)\n",
    "if is_zip:\n",
    "    print(f\"{zip_path} is a valid zip file.\")\n",
    "else:\n",
    "    print(f\"{zip_path} is not a valid zip file or is corrupted.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Source directory /teamspace/studios/this_studio/imgs does not exist.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Base directory containing source folders\n",
    "source_base_dir = '/teamspace/studios/this_studio/imgs'\n",
    "\n",
    "# Target base directory to store subfolders with JSON files\n",
    "target_base_dir = '/teamspace/studios/this_studio/processed_jsons'\n",
    "\n",
    "# Ensure the target directory exists\n",
    "if not os.path.exists(target_base_dir):\n",
    "    os.makedirs(target_base_dir)\n",
    "\n",
    "# Check if the source directory exists\n",
    "if not os.path.exists(source_base_dir):\n",
    "    print(f\"Error: Source directory {source_base_dir} does not exist.\")\n",
    "else:\n",
    "    # Loop through each directory in the source base directory\n",
    "    for dirname in sorted(os.listdir(source_base_dir)):\n",
    "        if dirname.startswith('xmlab'):  # Check if the directory name starts with 'xmlab'\n",
    "            source_dir_path = os.path.join(source_base_dir, dirname)\n",
    "            json_file_path = os.path.join(source_dir_path, 'detection.json')\n",
    "\n",
    "            if os.path.isfile(json_file_path):  # Check if the JSON file exists\n",
    "                # Create a new subdirectory for this JSON file in the target directory\n",
    "                new_subdir_name = f\"{dirname}detection\"\n",
    "                target_subdir_path = os.path.join(target_base_dir, new_subdir_name)\n",
    "                if not os.path.exists(target_subdir_path):\n",
    "                    os.makedirs(target_subdir_path)\n",
    "\n",
    "                # Define the target file path\n",
    "                target_file_path = os.path.join(target_subdir_path, 'detection.json')\n",
    "\n",
    "                # Copy the JSON file to the new location\n",
    "                shutil.copy2(json_file_path, target_file_path)\n",
    "                print(f\"File {json_file_path} copied to {target_file_path}\")\n",
    "            else:\n",
    "                print(f\"No detection.json found in {source_dir_path}\")\n",
    "        else:\n",
    "            print(f\"Skipped {dirname} as it does not match the 'xmlab*' pattern\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import shutil\n",
    "\n",
    "def has_numerical_values(data):\n",
    "    \"\"\"Recursively search for any numerical value in JSON data.\"\"\"\n",
    "    if isinstance(data, dict):\n",
    "        return any(has_numerical_values(v) for v in data.values())\n",
    "    elif isinstance(data, list):\n",
    "        return any(has_numerical_values(item) for item in data)\n",
    "    elif isinstance(data, (int, float)):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "# Base directory containing the processed JSON folders\n",
    "base_dir = '/teamspace/studios/this_studio/processed_jsons'\n",
    "# New base directory for only numerical detections\n",
    "numerical_base_dir = '/teamspace/studios/this_studio/numerical_detections'\n",
    "\n",
    "# Ensure the target directory exists\n",
    "if not os.path.exists(numerical_base_dir):\n",
    "    os.makedirs(numerical_base_dir)\n",
    "\n",
    "# Loop through each subdirectory in the base directory\n",
    "for subdir in os.listdir(base_dir):\n",
    "    subdir_path = os.path.join(base_dir, subdir)\n",
    "    json_file_path = os.path.join(subdir_path, 'detection.json')\n",
    "\n",
    "    if os.path.isfile(json_file_path):\n",
    "        # Read the JSON file\n",
    "        with open(json_file_path, 'r') as file:\n",
    "            try:\n",
    "                data = json.load(file)\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"Failed to decode JSON in file {json_file_path}\")\n",
    "                continue\n",
    "\n",
    "        # Check if the JSON data contains any numerical values\n",
    "        if has_numerical_values(data):\n",
    "            # Prepare a similar directory structure in the numerical detections directory\n",
    "            numerical_subdir_path = os.path.join(numerical_base_dir, subdir)\n",
    "            if not os.path.exists(numerical_subdir_path):\n",
    "                os.makedirs(numerical_subdir_path)\n",
    "\n",
    "            # Define the target file path in the new directory\n",
    "            target_file_path = os.path.join(numerical_subdir_path, 'detection.json')\n",
    "\n",
    "            # Copy the JSON file to the new location\n",
    "            shutil.copy2(json_file_path, target_file_path)\n",
    "            print(f\"File {json_file_path} copied to {target_file_path}\")\n",
    "        else:\n",
    "            print(f\"Removed {json_file_path} as it contains no numerical values\")\n",
    "    else:\n",
    "        print(f\"No detection.json file found in {subdir_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def count_directories(path):\n",
    "    \"\"\"Count directories in a given path.\"\"\"\n",
    "    return sum(1 for entry in os.listdir(path) if os.path.isdir(os.path.join(path, entry)))\n",
    "\n",
    "# Paths to the directories\n",
    "processed_json_dir = '/teamspace/studios/this_studio/processed_jsons'\n",
    "numerical_detections_dir = '/teamspace/studios/this_studio/numerical_detections'\n",
    "\n",
    "# Count directories in both paths\n",
    "processed_count = count_directories(processed_json_dir)\n",
    "numerical_count = count_directories(numerical_detections_dir)\n",
    "\n",
    "# Print the counts and the difference\n",
    "print(f\"Total directories in processed_jsons: {processed_count}\")\n",
    "print(f\"Total directories in numerical_detections: {numerical_count}\")\n",
    "print(f\"Number of directories removed (no numerical data): {processed_count - numerical_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Define source, bounding box, and mask directories\n",
    "source_dir = '/teamspace/studios/this_studio/numerical_detections'\n",
    "bounding_box_dir = '/teamspace/studios/this_studio/bounding_box'\n",
    "mask_dir = '/teamspace/studios/this_studio/mask'\n",
    "\n",
    "# Ensure the bounding box and mask directories exist\n",
    "os.makedirs(bounding_box_dir, exist_ok=True)\n",
    "os.makedirs(mask_dir, exist_ok=True)\n",
    "\n",
    "# Define bounding box indices based on your provided list\n",
    "bounding_box_indices = set(range(121, 166)) | set(range(156, 178)) | set(range(295, 356)) | set(range(388, 390))\n",
    "\n",
    "# Process each subdirectory in the source directory\n",
    "for subdir in os.listdir(source_dir):\n",
    "    # Extract numeric part assuming format 'xmlab<number>' possibly followed by additional text\n",
    "    # This regex matches numbers right after 'xmlab'\n",
    "    subdir_index_str = ''.join(filter(str.isdigit, subdir[len('xmlab'):]))  # Get numeric part\n",
    "    if subdir_index_str:\n",
    "        subdir_index = int(subdir_index_str)  # Convert to integer\n",
    "        subdir_path = os.path.join(source_dir, subdir)\n",
    "\n",
    "        if subdir_index in bounding_box_indices:\n",
    "            # Move to bounding box directory\n",
    "            target_subdir_path = os.path.join(bounding_box_dir, subdir)\n",
    "        else:\n",
    "            # Move to mask directory\n",
    "            target_subdir_path = os.path.join(mask_dir, subdir)\n",
    "\n",
    "        # Move the folder\n",
    "        shutil.move(subdir_path, target_subdir_path)\n",
    "        print(f\"Moved {subdir} to {target_subdir_path}\")\n",
    "\n",
    "print(\"Files have been organized into bounding box and mask folders.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def count_folders(directory):\n",
    "    \"\"\"Count the number of directories within a specified directory.\"\"\"\n",
    "    return sum(1 for item in os.listdir(directory) if os.path.isdir(os.path.join(directory, item)))\n",
    "\n",
    "# Define the paths to the bounding box and mask directories\n",
    "bounding_box_dir = '/teamspace/studios/this_studio/bounding_box'\n",
    "mask_dir = '/teamspace/studios/this_studio/mask'\n",
    "\n",
    "# Count the directories in each\n",
    "bounding_box_count = count_folders(bounding_box_dir)\n",
    "mask_count = count_folders(mask_dir)\n",
    "\n",
    "# Print the counts\n",
    "print(f\"Number of folders in bounding box directory: {bounding_box_count}\")\n",
    "print(f\"Number of folders in mask directory: {mask_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Directory to check\n",
    "bounding_box_dir = '/teamspace/studios/this_studio/bounding_box'\n",
    "\n",
    "# List all folders and sort them numerically based on the embedded number\n",
    "folders = sorted(os.listdir(bounding_box_dir), key=lambda x: int(''.join(filter(str.isdigit, x))))\n",
    "\n",
    "# Print all folders\n",
    "for folder in folders:\n",
    "    print(folder)\n",
    "\n",
    "# Optionally, count them\n",
    "print(f\"Total folders found: {len(folders)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Define the source and destination directories\n",
    "source_dir = '/teamspace/studios/this_studio/processed_jsons'\n",
    "destination_dir = '/teamspace/studios/this_studio/bounding_box'\n",
    "\n",
    "# List of missing folders to move\n",
    "missing_folders = ['xmlab178detection', 'xmlab356detection', 'xmlab390detection']\n",
    "\n",
    "# Loop through the missing folders and move them if found\n",
    "for folder in missing_folders:\n",
    "    source_folder_path = os.path.join(source_dir, folder)\n",
    "    destination_folder_path = os.path.join(destination_dir, folder)\n",
    "\n",
    "    # Check if the folder exists in the source directory\n",
    "    if os.path.exists(source_folder_path):\n",
    "        # Move the folder to the bounding box directory\n",
    "        shutil.move(source_folder_path, destination_folder_path)\n",
    "        print(f\"Moved {folder} to the bounding box directory.\")\n",
    "    else:\n",
    "        print(f\"Folder {folder} not found in the processed JSON directory.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Define the source and destination directories\n",
    "source_dir = '/teamspace/studios/this_studio/processed_jsons'\n",
    "destination_dir = '/teamspace/studios/this_studio/bounding_box'\n",
    "\n",
    "# Generate a list of missing folders based on your specifications\n",
    "missing_folders = [f'xmlab{num}detection' for num in [120] + list(range(179, 200)) + list(range(391, 394))]\n",
    "\n",
    "# Process each folder, moving it if found in the source directory\n",
    "for folder_name in missing_folders:\n",
    "    source_folder_path = os.path.join(source_dir, folder_name)\n",
    "    destination_folder_path = os.path.join(destination_dir, folder_name)\n",
    "\n",
    "    # Check if the folder exists in the source directory\n",
    "    if os.path.exists(source_folder_path):\n",
    "        # Move the folder to the bounding box directory\n",
    "        shutil.move(source_folder_path, destination_folder_path)\n",
    "        print(f\"Moved {folder_name} to the bounding box directory.\")\n",
    "    else:\n",
    "        print(f\"Folder {folder_name} not found in the processed JSON directory.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Define the path to the bounding box directory\n",
    "bounding_box_dir = '/teamspace/studios/this_studio/bounding_box'\n",
    "\n",
    "# Define the ranges to check\n",
    "ranges_to_check = list(range(295, 394)) + list(range(120, 200))  # Combines both ranges into one list\n",
    "\n",
    "# Function to generate folder names based on the specified range\n",
    "def generate_folder_name(num):\n",
    "    return f\"xmlab{num}detection\"\n",
    "\n",
    "# Check each folder in the defined ranges\n",
    "missing_folders = []\n",
    "for num in ranges_to_check:\n",
    "    folder_name = generate_folder_name(num)\n",
    "    folder_path = os.path.join(bounding_box_dir, folder_name)\n",
    "    # Check if the folder exists\n",
    "    if not os.path.exists(folder_path):\n",
    "        missing_folders.append(folder_name)\n",
    "\n",
    "# Report the findings\n",
    "if missing_folders:\n",
    "    print(\"The following folders are missing:\")\n",
    "    for folder in missing_folders:\n",
    "        print(folder)\n",
    "else:\n",
    "    print(\"All folders from xmlab295 to xmlab393 and xmlab120 to xmlab199 are present in the bounding box directory.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Directory to check\n",
    "bounding_box_dir = '/teamspace/studios/this_studio/bounding_box'\n",
    "\n",
    "# List all folders and sort them numerically based on the embedded number\n",
    "folders = sorted(os.listdir(bounding_box_dir), key=lambda x: int(''.join(filter(str.isdigit, x))))\n",
    "\n",
    "# Print all folders\n",
    "for folder in folders:\n",
    "    print(folder)\n",
    "\n",
    "# Optionally, count them\n",
    "print(f\"Total folders found: {len(folders)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Define the source and destination directories\n",
    "source_dir = '/teamspace/studios/this_studio/processed_jsons'\n",
    "destination_dir = '/teamspace/studios/this_studio/bounding_box'\n",
    "\n",
    "# Generate a list of folders to move, from xmlab357detection to xmlab387detection\n",
    "missing_folders = [f'xmlab{num}detection' for num in range(357, 388)]\n",
    "\n",
    "# Process each folder, moving it if found in the source directory\n",
    "for folder_name in missing_folders:\n",
    "    source_folder_path = os.path.join(source_dir, folder_name)\n",
    "    destination_folder_path = os.path.join(destination_dir, folder_name)\n",
    "\n",
    "    # Check if the folder exists in the source directory\n",
    "    if os.path.exists(source_folder_path):\n",
    "        # Move the folder to the bounding box directory\n",
    "        shutil.move(source_folder_path, destination_folder_path)\n",
    "        print(f\"Moved {folder_name} to the bounding box directory.\")\n",
    "    else:\n",
    "        print(f\"Folder {folder_name} not found in the processed JSON directory.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Define the directories\n",
    "bounding_box_dir = '/teamspace/studios/this_studio/bounding_box'\n",
    "mask_dir = '/teamspace/studios/this_studio/mask'\n",
    "\n",
    "# Get lists of folders in both directories\n",
    "bounding_box_folders = set(os.listdir(bounding_box_dir))\n",
    "mask_folders = set(os.listdir(mask_dir))\n",
    "\n",
    "# Find intersections (folders that should not be in the mask directory)\n",
    "intersecting_folders = bounding_box_folders.intersection(mask_folders)\n",
    "\n",
    "# Remove intersecting folders from the mask directory\n",
    "for folder in intersecting_folders:\n",
    "    folder_path = os.path.join(mask_dir, folder)\n",
    "    # Remove the folder entirely\n",
    "    shutil.rmtree(folder_path)\n",
    "    print(f\"Removed {folder} from the mask directory as it was found in the bounding box directory.\")\n",
    "\n",
    "# Optionally, report remaining valid folders\n",
    "remaining_mask_folders = set(os.listdir(mask_dir))\n",
    "print(\"Remaining folders in the mask directory are confirmed to be exclusive from the bounding box directory.\")\n",
    "for folder in remaining_mask_folders:\n",
    "    print(folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "def zip_directory(folder_path, output_path):\n",
    "    \"\"\"Zips the contents of a folder into a zip file at the specified output path.\"\"\"\n",
    "    with zipfile.ZipFile(output_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "        for root, dirs, files in os.walk(folder_path):\n",
    "            for file in files:\n",
    "                # Create a proper archive path to keep the directory structure\n",
    "                archive_path = os.path.relpath(os.path.join(root, file), os.path.join(folder_path, '..'))\n",
    "                zipf.write(os.path.join(root, file), archive_path)\n",
    "        print(f\"Created zip archive: {output_path}\")\n",
    "\n",
    "# Define the directories to zip\n",
    "directories_to_zip = {\n",
    "    'mask': '/teamspace/studios/this_studio/mask',\n",
    "    'numerical_detections': '/teamspace/studios/this_studio/numerical_detections',\n",
    "    'bounding_box': '/teamspace/studios/this_studio/bounding_box'\n",
    "}\n",
    "\n",
    "# Loop through the directories and zip each one\n",
    "for key, path in directories_to_zip.items():\n",
    "    output_zip_path = f\"/teamspace/studios/this_studio/{key}.zip\"\n",
    "    zip_directory(path, output_zip_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "def copy_files(src_dir, dest_dir):\n",
    "    \"\"\"Copy all relevant files from src_dir to dest_dir.\"\"\"\n",
    "    # Define relevant files\n",
    "    relevant_files = ['source.jpg', 'mask.png', 'detection.json', 'question.json']\n",
    "    for file_name in relevant_files:\n",
    "        src_file = os.path.join(src_dir, file_name)\n",
    "        dest_file = os.path.join(dest_dir, file_name)\n",
    "        # Check if the source file exists before copying\n",
    "        if os.path.exists(src_file):\n",
    "            shutil.copy2(src_file, dest_file)\n",
    "            print(f\"Copied {src_file} to {dest_file}\")\n",
    "        else:\n",
    "            print(f\"File {src_file} does not exist, skipping.\")\n",
    "\n",
    "def consolidate_files(imgs_base_path, mask_base_path, bounding_box_base_path):\n",
    "    \"\"\"Consolidate files from imgs directory to respective mask or bounding_box directories.\"\"\"\n",
    "    # Loop through all subdirectories in imgs base path\n",
    "    for subdir in os.listdir(imgs_base_path):\n",
    "        src_dir = os.path.join(imgs_base_path, subdir)\n",
    "        dest_dir = None\n",
    "        # Check if the subdirectory corresponds to a mask or bounding box instance\n",
    "        if subdir.endswith(\"detection\"):\n",
    "            subdir_num = int(subdir.replace(\"xmlab\", \"\").replace(\"detection\", \"\"))\n",
    "            if subdir_num >= 120:  # Assuming all instances with 120 or above go to bounding_box\n",
    "                dest_dir = os.path.join(bounding_box_base_path, subdir)\n",
    "            else:  # Otherwise, they go to mask\n",
    "                dest_dir = os.path.join(mask_base_path, subdir)\n",
    "        \n",
    "        if dest_dir and not os.path.exists(dest_dir):\n",
    "            os.makedirs(dest_dir)\n",
    "\n",
    "        # Copy relevant files\n",
    "        if dest_dir:\n",
    "            copy_files(src_dir, dest_dir)\n",
    "\n",
    "# Define base paths\n",
    "imgs_base_path = '/teamspace/studios/this_studio/imgs'\n",
    "mask_base_path = '/teamspace/studios/this_studio/mask'\n",
    "bounding_box_base_path = '/teamspace/studios/this_studio/bounding_box'\n",
    "\n",
    "# Consolidate files\n",
    "consolidate_files(imgs_base_path, mask_base_path, bounding_box_base_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloudspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
